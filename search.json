[
  {
    "objectID": "ws24-25/sum.html",
    "href": "ws24-25/sum.html",
    "title": "My Uni Notes",
    "section": "",
    "text": "##Week 1\n###Lecture 1\n\ndate:\n\n###Lecture 2\n\ndate:\n\n##Week 2\n###Lecture 1\n\ndate:\n\n###Lecture 2\n\ndate:\n\n##Week 3\n###Lecture 1\n\ndate:\n\n###Lecture 2\n\ndate:\n\n##Week 4\n###Lecture 1\n\ndate:\n\n###Lecture 2\n\ndate:\n\n##Week 5\n###Lecture 1\n\ndate:\n\n###Lecture 2\n\ndate:\n\n##Week 6\n###Lecture 1\n\ndate:\n\n###Lecture 2\n\ndate:\n\n##Week 7\n###Lecture 1\n\ndate:\n\n###Lecture 2\n\ndate:\n\n##Week 8\n###Lecture 1\n\ndate:\n\n###Lecture 2\n\ndate:\n\n##Week 9\n###Lecture 1\n\ndate:\n\n###Lecture 2\n\ndate:\n\n##Week 10\n###Lecture 1\n\ndate:\n\n###Lecture 2\n\ndate:\n\n##Week 11\n###Lecture 1\n\ndate:\n\n###Lecture 2\n\ndate:\n\n##Week 12\n###Lecture 1\n\ndate:\n\n###Lecture 2\n\ndate:\n\n##Week 13\n###Lecture 1\n\ndate:\n\n###Lecture 2\n\ndate:\n\n##Week 14\n###Lecture 1\n\ndate:\n\n###Lecture 2\n\ndate:\n\n##Week 15\n###Lecture 1\n\ndate:\n\n###Lecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/its/index.html",
    "href": "ws24-25/its/index.html",
    "title": "IT-Security",
    "section": "",
    "text": "weekly summary\nnotes\nsolutions"
  },
  {
    "objectID": "ws24-25/its/index.html#section",
    "href": "ws24-25/its/index.html#section",
    "title": "IT-Security",
    "section": "",
    "text": "weekly summary\nnotes\nsolutions"
  },
  {
    "objectID": "ws24-25/isw/index.html",
    "href": "ws24-25/isw/index.html",
    "title": "Software Engineering",
    "section": "",
    "text": "weekly summary\nnotes\nsolutions",
    "crumbs": [
      "Software Engineering"
    ]
  },
  {
    "objectID": "ws24-25/isw/index.html#section",
    "href": "ws24-25/isw/index.html#section",
    "title": "Software Engineering",
    "section": "",
    "text": "weekly summary\nnotes\nsolutions",
    "crumbs": [
      "Software Engineering"
    ]
  },
  {
    "objectID": "ws24-25/ds/sum.html",
    "href": "ws24-25/ds/sum.html",
    "title": "My Uni Notes",
    "section": "",
    "text": "date:\n\n\n\n\n\ndate:"
  },
  {
    "objectID": "ws24-25/ds/sum.html#week-1",
    "href": "ws24-25/ds/sum.html#week-1",
    "title": "My Uni Notes",
    "section": "",
    "text": "date:\n\n\n\n\n\ndate:"
  },
  {
    "objectID": "ws24-25/ds/sum.html#week-2",
    "href": "ws24-25/ds/sum.html#week-2",
    "title": "My Uni Notes",
    "section": "Week 2",
    "text": "Week 2\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/ds/sum.html#week-3",
    "href": "ws24-25/ds/sum.html#week-3",
    "title": "My Uni Notes",
    "section": "Week 3",
    "text": "Week 3\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/ds/sum.html#week-4",
    "href": "ws24-25/ds/sum.html#week-4",
    "title": "My Uni Notes",
    "section": "Week 4",
    "text": "Week 4\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/ds/sum.html#week-5",
    "href": "ws24-25/ds/sum.html#week-5",
    "title": "My Uni Notes",
    "section": "Week 5",
    "text": "Week 5\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/ds/sum.html#week-6",
    "href": "ws24-25/ds/sum.html#week-6",
    "title": "My Uni Notes",
    "section": "Week 6",
    "text": "Week 6\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/ds/sum.html#week-7",
    "href": "ws24-25/ds/sum.html#week-7",
    "title": "My Uni Notes",
    "section": "Week 7",
    "text": "Week 7\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/ds/sum.html#week-8",
    "href": "ws24-25/ds/sum.html#week-8",
    "title": "My Uni Notes",
    "section": "Week 8",
    "text": "Week 8\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/ds/sum.html#week-9",
    "href": "ws24-25/ds/sum.html#week-9",
    "title": "My Uni Notes",
    "section": "Week 9",
    "text": "Week 9\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/ds/sum.html#week-10",
    "href": "ws24-25/ds/sum.html#week-10",
    "title": "My Uni Notes",
    "section": "Week 10",
    "text": "Week 10\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/ds/sum.html#week-11",
    "href": "ws24-25/ds/sum.html#week-11",
    "title": "My Uni Notes",
    "section": "Week 11",
    "text": "Week 11\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/ds/sum.html#week-12",
    "href": "ws24-25/ds/sum.html#week-12",
    "title": "My Uni Notes",
    "section": "Week 12",
    "text": "Week 12\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/ds/sum.html#week-13",
    "href": "ws24-25/ds/sum.html#week-13",
    "title": "My Uni Notes",
    "section": "Week 13",
    "text": "Week 13\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/ds/sum.html#week-14",
    "href": "ws24-25/ds/sum.html#week-14",
    "title": "My Uni Notes",
    "section": "Week 14",
    "text": "Week 14\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/ds/sum.html#week-15",
    "href": "ws24-25/ds/sum.html#week-15",
    "title": "My Uni Notes",
    "section": "Week 15",
    "text": "Week 15\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws23-24/num/sum.html",
    "href": "ws23-24/num/sum.html",
    "title": "Num Weekly Summary",
    "section": "",
    "text": "W01/VL01\n\ndate:\nsummary:\n\nW01/VL02\n\ndate:\nsummary:\n\nW02/VL03\n\ndate:\nsummary:\n\nW02/VL04:\n\ndate:\nsummary:\n\nW03/VL05\n\ndate: 31/10/2023, Tue\nsummary: \\(LR\\)-Decomposition, uniqueness, existence, algorithm, complexity, error analysis\n\nScript pages: 21 (satz 2.5) - 28 (2.3 Error Analysis of LR)\nLR Zerlegung ist eindeutig\nProduct of two triangular matrices is also triangular (left or right)\nInverse of a triangular matrix is triangular (left or right)\nProduct of two left-triangular matrices with \\(a_{ii} = 1\\) is also a left-triangular matrix with \\(\\tilde{a}_{ii} = 1\\)\n\\(LR\\)-Decomposition method using Gauss decomposition (Alg 2.7) (?).\nExistence of the \\(LR\\)-decomposition (Satz 2.8)\nPractical version of \\(LR\\)-decomposition Algorithm (not Alg 2.7) saves space (Alg 2.9).\nComplexity of Alg 2.9 and solving a LSE (De: LGS)\nError analysis of \\(LR\\)-Decomposition.\n\n\nW03/VL06\n\ndate: 02/11/23, Thu\nsummary: Script 28 - 33. Error estimation of Alg 2.9, forwards and backwards error, conditioning of a function, conditioning number.\n\nError estimation of Alg 2.9 with proof (Lemma 2.13 & Satz 2.14)\nAposteriori error estimation of Alg 2.9 (Satz 2.16)\nrelationship between backwards and forwards error, a python example demonstrating that they aren’t necessarily related (?)\nConditioning of a function (Ch 2.4.1).\nConditioning number\n\n\nW04/VL07\n\ndate: 07/11/23, Tue\nsummary: Script 33 - 42.\n\nQuestion: How much effect does the error in \\(A\\) & \\(b\\) have on the solutuion of an LEQ/LGS?\nConditioning of a matrix & its proof. (Prop 2.20)\nError analysis of LEQ/LGS’s (Ch 2.4.3)\nConvergent Matrix sequences and matrix series (Ch 2.4.4.)\n\nNeumann Series (2.4.9, P:37)\nSpectral radius of a matrix\n\nConvergent Matrix sequences are used in the proof of error estimation of LEQ/LGS’s. Proof of 2.2.1\nPivoting Strategies to increase \\(LR\\)-decomposition algorithm stability (Ch. 2.5) via exchanging rows during the steps of the algorithm.\n\nPermutation Matrix (Def 2.25)\n\n\n\nW04/VL08\n\ndate: 09/11/23, Thu\nsummary: Script 43 - 51\n\nnote: numbering shifted 1 up, due to a new example\nAlg. 2.27: \\(LR\\)-Decomposition with column pivot search.\n\nSatz 2.30: \\(\\forall\\) regular matrix \\(A \\in \\mathbb{R}^{n\\times n}\\, \\exists\\) a Permutations matrix \\(P_{\\pi}\\), s.t \\(LR = P_{\\pi}A\\) and its proof.\nA problematic matrix for this method: Wilkinson matrix. Such problems can be avoided with “Full Pivot Search/Vollpivotsuche”.\nBut fullpivot search has the disatvantageous complexity \\(\\mathcal{O}(n^3)\\)\n\nCholesky Decomposition: An efficient method for Symmetric Positive Definite (SPD) Matrices.\n\nDefinition & Properties of SPD matrices. (Def 2.32 & Satz 2.33)\nSatz 3.34: \\(A\\in\\mathbb{R}^{n\\times n} \\text{\\, SPD \\, }\\Rightarrow \\exists \\text{\\, upper triangular} \\, R\\in \\mathbb{R}^{n\\times n} \\text{\\, s.t.\\, } A = R^TR\\) (Cholesky decomposition)\nProof of Satz 3.34\nAlgorithm for Cholesky Decomposition (Alg 2.35) and its complexity (\\(\\frac{n^3}{3} + \\mathcal{O}(n^2)\\)). (2 times more efficient than usual decommposition)\n\n\\(LR\\)-Decomposition for Band-matrices\n\nSparce matrices (schwach besetzte matrix) \\(\\approx\\) many entries are 0.\nhow sparce matrices are stored efficiently: For example\n\nA = 0 5 0    C = (2, 3) {non-nul columns}\n    0 0 0    R = (1, 3) {non-null rows}\n    0 0 7    X = (5, 7) {actual entries in these coordinates}\n\nDefinition of a band matrix (Def 2.38)\n\\(LR\\)-decomposition for Band matrices.\n\n\n\nW05/VL09\n\ndate: 14.11.23, Tue\nsummary: Skript 51 - 55 (togehter with topics form appendix)\n\nReview of some LA topics (from Appendix):\n\nDef of orthogonal matrix\nDef of unitary matrix\nLemma A.57/Satz A.58: Singular value decomposition (SVD) and its proof.\nProgramming example demonstrating uses of SVD for image compression.\nProp A.61 regarding SVD (?)\n\nIntro to new Ch 3 - Interpolation & Approximation\n\nOverview of different types of interpolating functions: polynomial, rational (polynomial), spline, neural network\nIntro Polynomial Interpolation:\n\nDef of vector space of polynomials of degree \\(n\\): \\(\\mathbb{P}_n\\).\nDef 3.1: Lagrange Interpolation Polynomials\n\n\n\n\nW05/VL10\n\ndate: 16.11.23, Thu\nsummary: Skript: 55 - 64\n\nLagrange interpolation\n\nLagrange polynomials \\(\\{l_i\\}_{i=0\\dots n}\\) Form a basis for \\(\\mathbb{P}_n\\) & its proof.\n\nGeneral interpolation with a general basis \\(\\{b_i\\}_{i=0\\dots n}\\) \\(\\Rightarrow\\) Vandermonde Matrix. note: Vandermonde matrix for Lagrange Basis is simply the identity matrix. Vandermonde matrix is very badly conditioned for the monomial basis \\(\\{x^i\\}_{i=0}^n\\)\nError analysis of Lagrange interpolation. Certain properties of the function that is to be interpolated determine the precision of the error analysis (like the smoothness of the function.) (Satz 3.6)\nNeville’s Schema\n\n\nW06/VL11\n\ndate: 21.11.23, Tue\nsummary: Skript 64 - 71\n\nNewton Interpolation (Ch 3.5)\n\nDividierende Differenzen\nLemma 3.11 and its proof via induction.\n\nIntepolation error\nHermite Interpolation\n(3.7 is skipped)\n3.8 Conditioning and Approximation\nWeierstrass Theorem (3.25)\n\n\nW06/VL12\n\ndate: 23.11.23, Thu\nsummary: Skript 71 - 81\n\nreview of error of polynomial interpolation: Bsp 3.21, 3.22.\nRunge Phenomenon\nWeierstrass Theorem (3.25) and its relationship to polynomial interpolation.\nError of the best approximation (Satz 3.26)\n\nDef 3.23: Lebesgue Constant \\(\\Lambda_n\\)\n\nConditioning of the interpolation, what happens when we interpolate \\(f + \\delta\\) instead of \\(f\\)?\nIf the function is only known to be continuous (but not necessarily differentiable), there is another measure for how strong a function “fluctuates”: Modulus of continuity (Stetigkeitsmodul) (Def 3.27)\nJackson’s Theorem (3.28) given without proof.\nCorollary (3.29) - its proof.\nHow to keep \\(\\Lambda_n\\) small? \\(\\rightarrow\\) Chebyshev Interpolation, Chebyshev Points\n\nGoal: find appropriate points \\(\\{x_i\\}_{i=1\\dots n}\\) s.t. \\(\\Lambda_n\\) is minimal.\nDefinition of Chebyshev Points (Def 3.30): \\(x_i^{(n + 1)} = \\cos{(\\frac{2i + 1}{2n + 2}\\pi)}\\) \nDefinition of Chebyshev Polynomials (Def 3.32)\nLemma 3.33 - some properties of chebyshev polynomials\n\n\n\nW07/VL13\n\ndate: 28.11.23\nsummary: Skript 81 - 96 (some pages were skipped)\n\nClenshaw-Curtis points\nSatz 3.34\nProofs regarding Lebesgue Constats are skipped.\nLemma 3.40:\nSkip until Spline Interpolation\nSpline Interpolation:\n\nError of spline interpolation\nCubic splines"
  },
  {
    "objectID": "ws23-24/ipi/sum.html",
    "href": "ws23-24/ipi/sum.html",
    "title": "IPI Weekly Summary",
    "section": "",
    "text": "Week 1/~\n\ndate:\nsummary:\n\nWeek 1/~\n\ndate:\nsummary:\n\nWeek 2/VL 1\n\ndate:\nsummary:\n\nWeek 2/VL 2:\n\ndate:\nsummary:"
  },
  {
    "objectID": "ws23-24/index.html#courses",
    "href": "ws23-24/index.html#courses",
    "title": "WS 23/24",
    "section": "Courses",
    "text": "Courses\n\nNum\nIPI",
    "crumbs": [
      "Bachelor",
      "WS 23/24"
    ]
  },
  {
    "objectID": "ss25/scicomp/index.html",
    "href": "ss25/scicomp/index.html",
    "title": "Object Oriented Scientific Computing with C++",
    "section": "",
    "text": "notes\nsolutions\nweekly-summary",
    "crumbs": [
      "scicomp"
    ]
  },
  {
    "objectID": "ss25/ibn/sum/w04.html",
    "href": "ss25/ibn/sum/w04.html",
    "title": "Week 4",
    "section": "",
    "text": "pthread_cond_t, boolean variable cv.(it is actually a signalling / triggering variable)\nposix state variables API: (Slide 11)\n\ncond_wait(condition, mut)\ncond_signal(condition)\ncond_broadcast(condition): set condition to true, wake all sleeping\n\nFlow of using cond vars (condition variables) (Slide 12 important):\n\n(A)-event producer, (B)-event consumer\nexample: archive a data automatically (Slide 14 important)\n\nSemaphores with active waiting - pseudocode. (semaphores require locks, locks require hardware solutions Klausurrelevant)\n\nactive waiting: infinite loop (ineffective). instead \\(\\Rightarrow\\) sleeping.\n\nsemaphores toy implementation in C with structs without active waiting, rather with sleep, and block on the system level.\n\n\n\n\nSlide: 29, …\n\nkeyword synchronized.\nkeywords wait() and notify().\n\nRace conditions, synchronization, semaphores, locks, mutexes are all Klausurrelevant.\n\n\n\n\nProcesses are in general independent and do not have an effect on each other. Nevertheless cooperation among processes is useful. How to achieve the cooperation between processes \\(\\Rightarrow\\) IPC.\n2 main IPC families:\n\nmessage passing - MP (safer)\nshared-memory - SM (faster)",
    "crumbs": [
      "Weekly Summary",
      "Week 4"
    ]
  },
  {
    "objectID": "ss25/ibn/sum/w04.html#vl-7---05.05.25",
    "href": "ss25/ibn/sum/w04.html#vl-7---05.05.25",
    "title": "Week 4",
    "section": "",
    "text": "pthread_cond_t, boolean variable cv.(it is actually a signalling / triggering variable)\nposix state variables API: (Slide 11)\n\ncond_wait(condition, mut)\ncond_signal(condition)\ncond_broadcast(condition): set condition to true, wake all sleeping\n\nFlow of using cond vars (condition variables) (Slide 12 important):\n\n(A)-event producer, (B)-event consumer\nexample: archive a data automatically (Slide 14 important)\n\nSemaphores with active waiting - pseudocode. (semaphores require locks, locks require hardware solutions Klausurrelevant)\n\nactive waiting: infinite loop (ineffective). instead \\(\\Rightarrow\\) sleeping.\n\nsemaphores toy implementation in C with structs without active waiting, rather with sleep, and block on the system level.\n\n\n\n\nSlide: 29, …\n\nkeyword synchronized.\nkeywords wait() and notify().\n\nRace conditions, synchronization, semaphores, locks, mutexes are all Klausurrelevant.\n\n\n\n\nProcesses are in general independent and do not have an effect on each other. Nevertheless cooperation among processes is useful. How to achieve the cooperation between processes \\(\\Rightarrow\\) IPC.\n2 main IPC families:\n\nmessage passing - MP (safer)\nshared-memory - SM (faster)",
    "crumbs": [
      "Weekly Summary",
      "Week 4"
    ]
  },
  {
    "objectID": "ss25/ibn/sum/w04.html#vl-8---07.05.25",
    "href": "ss25/ibn/sum/w04.html#vl-8---07.05.25",
    "title": "Week 4",
    "section": "VL 8 - 07.05.25",
    "text": "VL 8 - 07.05.25\n\nIPC (cont.)\nIPC has variouis APIs / Implementations\n\ndata streams: pipes, sockets, message queues, terminal, …\nevents\nremote procedure call\nshared memory\n\n\nMessage Passing\nmessage passing can be blocking and non-blocking;\n\nblocking = synchronous,\nnon-blocking = asynchronous.\n\nDistributed IPC: communication between distinct computers\n\nsockets: they imitate data systems\nremote proecedure calls\nweb services:\n\n\n\nMessage Passing via Pipes\n\nAnonymous pipes\ninstead of\nls -R &gt;tmp-file.txt\ngrep -ci '\\.jpg$' tmp-file.txt\nwe can do:\nls -R | grep -ci '\\.jpg$' \n\ncommunication is realized by fork(): all the data etc is inherited by the child process.\nclosely related is: producer / consumer problem\n\n\n\nNamed Pipes\nbi-directional communication\n\n\nData descriptors / handles\nDD (file descriptor) is an integer (an index to a file data structure) and not a pointer.\nThere are standard DD values. Any time a process is started in Linux, three “files” are automatically opened that have the following DD values:\n\n0: stdin\n1: stdout\n2: stderr\n\nThese can be redirected in the shell. In order to achidve this the “hard-coded” DDs must “overwritten” \\(\\Rightarrow\\) dup2():\nint dup2(int srcDD, int targetDD)",
    "crumbs": [
      "Weekly Summary",
      "Week 4"
    ]
  },
  {
    "objectID": "ss25/ibn/sum/w02.html",
    "href": "ss25/ibn/sum/w02.html",
    "title": "Week 2",
    "section": "",
    "text": "os api’s:\n\na quick exmaple: system calls in windows, reading a data.\nAPI’s in Windows vs Posix\nWindows Subsystem for Linux (WSL)\n\n\n\n\n\nProcess: an active, executing program\na programm becomes a process when the OS loads the program code to the memory =&gt; same program can be started many times =&gt; multiple processes of the same program\nMemory of a process:\n\nstack: function calls, return addresses, variables local to the stack\nheap: dynamically allocated memory for objects and arbitrarily large data structures.\ndata: global variables, constants.\nprogram code.\n\nstack and heap grow towards each other.\nProcess Control Block (PCB): the way OS managemes processes (process bookkeeping) (implemented as struct in C.)\nProcess management: creation, deletion, etc\n\nfork(): creates an identical child-process.\nexecve(): replace the memory contents of a process.\nwaitpid(): wait for the ending of a child-process.\n_exit(): end the process\n\nexample: a (very) mimimal, toy shell - application of fork()\ninit() in Posix\nprocess creation in windows.\nprocess management\n\n\n\n\nfork\n\n\n\nparent and child processes can be synchonozied with a wait() command in conjunction with fork().\n\n## Tutorial\n\noverview of bash\ngreeting=\"Hello, world!\"\necho \"$greeting\"",
    "crumbs": [
      "Weekly Summary",
      "Week 2"
    ]
  },
  {
    "objectID": "ss25/ibn/sum/w02.html#vl-3---23.04.25",
    "href": "ss25/ibn/sum/w02.html#vl-3---23.04.25",
    "title": "Week 2",
    "section": "",
    "text": "os api’s:\n\na quick exmaple: system calls in windows, reading a data.\nAPI’s in Windows vs Posix\nWindows Subsystem for Linux (WSL)\n\n\n\n\n\nProcess: an active, executing program\na programm becomes a process when the OS loads the program code to the memory =&gt; same program can be started many times =&gt; multiple processes of the same program\nMemory of a process:\n\nstack: function calls, return addresses, variables local to the stack\nheap: dynamically allocated memory for objects and arbitrarily large data structures.\ndata: global variables, constants.\nprogram code.\n\nstack and heap grow towards each other.\nProcess Control Block (PCB): the way OS managemes processes (process bookkeeping) (implemented as struct in C.)\nProcess management: creation, deletion, etc\n\nfork(): creates an identical child-process.\nexecve(): replace the memory contents of a process.\nwaitpid(): wait for the ending of a child-process.\n_exit(): end the process\n\nexample: a (very) mimimal, toy shell - application of fork()\ninit() in Posix\nprocess creation in windows.\nprocess management\n\n\n\n\nfork\n\n\n\nparent and child processes can be synchonozied with a wait() command in conjunction with fork().\n\n## Tutorial\n\noverview of bash\ngreeting=\"Hello, world!\"\necho \"$greeting\"",
    "crumbs": [
      "Weekly Summary",
      "Week 2"
    ]
  },
  {
    "objectID": "ss25/ibn/sum/index.html",
    "href": "ss25/ibn/sum/index.html",
    "title": "Weekly Summary",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nWeek 1\n\n\nApr 14, 2025\n\n\n\n\nWeek 2\n\n\nApr 22, 2025\n\n\n\n\nWeek 3\n\n\nApr 29, 2025\n\n\n\n\nWeek 4\n\n\nMay 5, 2025\n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Weekly Summary"
    ]
  },
  {
    "objectID": "ss25/alda/sum/w04.html",
    "href": "ss25/alda/sum/w04.html",
    "title": "Week 4",
    "section": "",
    "text": "principle:\n\nsorintg from left to write (left to the current position is all sorted)\nselect the appropriate element in the right-side of the current position.\n\n\ndef selection_sort(a) :\n    N = len(a)\n    # invariant: sorted(a[0..i-1]) and a[0..i-1] &lt;= a[i..N-1]\n    for i in range(N - 1) :  # iteration\n        j = i \n        # k = i + 1\n        # invariant: a[j] == min(a[i..k-1])\n        for k in range(i + 1, N) : \n            if a[k] &lt; a[j] : j = k\n        a[i], a[j] = a[j], a[i]\n\na = [3, -1, 5, 10]\nselection_sort(a)\nprint(a)\n\n[-1, 3, 5, 10]\n\n\n\n\nHow many steps does selection sort take?\n\nobviously depends on N.\nestimating the runtime: \\(L(N) \\approx c \\cdot f(N)\\), where \\(f(N)\\) is some simple function (the formally correct versiono later with the \\(\\mathcal{O}(N)\\) notation)\n\nThe inner loop compares a[k] &lt; a[j] for each k in range(i + 1, N), so the number of comparisons decreases as i increases. Here’s the completed table based on the structure of the nested loops:\n\n\n\ni\nk\nnumber of comparisons\n\n\n\n\n0\n1 … N - 1\nN - 1\n\n\n1\n2 … N - 1\nN - 2\n\n\n2\n3 … N - 1\nN - 3\n\n\n…\n…\n…\n\n\nN-3\nN-2 … N - 1\n2\n\n\nN-2\nN - 1\n1\n\n\nN-1\n— (no iteration)\n0\n\n\n\nTotal number of comparisons:\nTo find the overall time complexity, sum all the comparisons:\n\\[\n(N - 1) + (N - 2) + \\dots + 1 = \\frac{N(N - 1)}{2}\n\\]\nSo, the time complexity of selection sort is O(N²) in the worst, average, and best cases (it always does the same number of comparisons).\nHow to make sorting functions generic so that they can be provided in libraries? \\(\\Rightarrow\\) API (Application Programming Interface), so that the user can choose the sorting criteria the following way:\n\ndef selection_sort2(a, key = lambda x : x): \n    N = len(a)\n    # i = 0\n    # invariant sorted(a[0..i]) and a[0..i-1] &lt;= a[]\n    for i in range(N - 1) :\n        m = i\n        for  k in range(i + 1, N) :\n            if key(a[k]) &lt; key(a[m]): m = k\n        a[i], a[m] = a[m], a[i]\n\nAssume we have an array that contains tuples of students:\n\nstudents = [(\"andrej\", 20, 1.3),\n            (\"igor\", 22, 2.7),\n            (\"olga\", 21, 1.7)]\n\nThen, the following way we could sort on different criteria:\n\nselection_sort2(students, lambda x : x[0]) # sort w.r.t. names\nprint(students)\nselection_sort2(students, lambda x : x[1]) # sort w.r.t. age\nprint(students)\nselection_sort2(students, lambda x : x[2]) # sort w.r.t. grade\nprint(students)\n\n[('andrej', 20, 1.3), ('igor', 22, 2.7), ('olga', 21, 1.7)]\n[('andrej', 20, 1.3), ('olga', 21, 1.7), ('igor', 22, 2.7)]\n[('andrej', 20, 1.3), ('olga', 21, 1.7), ('igor', 22, 2.7)]\n\n\n\n\n\n\nStable sorting preserves the original order of elements with equal keys, which is especially useful when sorting complex objects.\n\nExample: Given a = [(\"Abel\", 20), (\"Babel\", 20), (\"Frey\", 19)], initially sorted by name, sorting again by age using sort(a, key=lambda x: x[1]) yields a = [(\"Frey\", 19), (\"Abel\", 20), (\"Babel\", 20)].\n\nThe idea behind stable sorting is that you can first sort by a secondary criterion (e.g., names), then by a primary one (e.g., grades), and the final result will retain the secondary order within groups that share the same primary key. Without stability, you’d need to re-sort each group manually.\n\n\n\n\ninsertion sort is stable\ninsertion sort is the fastest algorithm for small N.\nPrinciple:\n\nsorts from left to right.\ncreate a hole in the correct position for the element a[i]\n\n\n\ndef insertion_sort(a):\n    N = len(a)\n    # i = 1\n    # sorted(a[0..i-1])\n    for i in range(1, N):\n        k = i\n        while k &gt; 0:\n            if a[k] &lt; a[k - 1]: \n                a[k - 1], a[k] = a[k], a[k - 1]\n            else: break\n            k = k - 1\n\na = [1, -3, 4, 10, -99]\ninsertion_sort(a)\nprint(a)\n\n[-99, -3, 1, 4, 10]\n\n\n\n\nRuntime of insertion sort depends on whether the array was sorted before hand. (In selection sort run time is always the same formula)\n\nCase 1(Best Case): array is already sorted \\(\\Rightarrow \\mathcal{O}(n)\\) , since inner while loop always executes the break statement immediately.\nCase 2 (Worst case): array is reverse sorted \\(\\Rightarrow \\mathcal{O}(n^2)\\) , since each inner while loop always executes the whole range of \\(i\\)s.\nCase 3 (Average case): Array is randomly sorted, i.e. intuitively somewhere in between sorted and reversly sorted. In this case the inner while loop breaks after \\(\\frac{i}{2}\\). Then the complexity can be written as\n\\[T(N) = \\frac{c}{2}(1 + 2 + \\ldots + (N - 1)) \\in \\mathcal{O}(N^2)\\]\n\n\n\n\n\n\nfaster sorter algorithms that run in \\(\\mathcal{O}(N\\cdot\\log{N})\\) and \\(\\mathcal{O}(N)\\) (bucket sort).\nsuch algoriths are faster because they employ the “divide and conquer” principle (recursion):\n\ndivide the problem to smaller sub-problems and solve the smaller problems\ncombine the smaller solutions\n\ntwo classic exmples of such algorithms:\n\nmerge sort:\n\ndivide the array in two equal parts\nsorts the half errays\nmerge the sorted half arrays\n\nquick sort:\n\nchoose a pivot element\ndivide the array into “smaller than pivot” and “greater than pivot”\nsort the individual parts.",
    "crumbs": [
      "Weekly Summary",
      "Week 4"
    ]
  },
  {
    "objectID": "ss25/alda/sum/w04.html#vl-7---06.05.25",
    "href": "ss25/alda/sum/w04.html#vl-7---06.05.25",
    "title": "Week 4",
    "section": "",
    "text": "principle:\n\nsorintg from left to write (left to the current position is all sorted)\nselect the appropriate element in the right-side of the current position.\n\n\ndef selection_sort(a) :\n    N = len(a)\n    # invariant: sorted(a[0..i-1]) and a[0..i-1] &lt;= a[i..N-1]\n    for i in range(N - 1) :  # iteration\n        j = i \n        # k = i + 1\n        # invariant: a[j] == min(a[i..k-1])\n        for k in range(i + 1, N) : \n            if a[k] &lt; a[j] : j = k\n        a[i], a[j] = a[j], a[i]\n\na = [3, -1, 5, 10]\nselection_sort(a)\nprint(a)\n\n[-1, 3, 5, 10]\n\n\n\n\nHow many steps does selection sort take?\n\nobviously depends on N.\nestimating the runtime: \\(L(N) \\approx c \\cdot f(N)\\), where \\(f(N)\\) is some simple function (the formally correct versiono later with the \\(\\mathcal{O}(N)\\) notation)\n\nThe inner loop compares a[k] &lt; a[j] for each k in range(i + 1, N), so the number of comparisons decreases as i increases. Here’s the completed table based on the structure of the nested loops:\n\n\n\ni\nk\nnumber of comparisons\n\n\n\n\n0\n1 … N - 1\nN - 1\n\n\n1\n2 … N - 1\nN - 2\n\n\n2\n3 … N - 1\nN - 3\n\n\n…\n…\n…\n\n\nN-3\nN-2 … N - 1\n2\n\n\nN-2\nN - 1\n1\n\n\nN-1\n— (no iteration)\n0\n\n\n\nTotal number of comparisons:\nTo find the overall time complexity, sum all the comparisons:\n\\[\n(N - 1) + (N - 2) + \\dots + 1 = \\frac{N(N - 1)}{2}\n\\]\nSo, the time complexity of selection sort is O(N²) in the worst, average, and best cases (it always does the same number of comparisons).\nHow to make sorting functions generic so that they can be provided in libraries? \\(\\Rightarrow\\) API (Application Programming Interface), so that the user can choose the sorting criteria the following way:\n\ndef selection_sort2(a, key = lambda x : x): \n    N = len(a)\n    # i = 0\n    # invariant sorted(a[0..i]) and a[0..i-1] &lt;= a[]\n    for i in range(N - 1) :\n        m = i\n        for  k in range(i + 1, N) :\n            if key(a[k]) &lt; key(a[m]): m = k\n        a[i], a[m] = a[m], a[i]\n\nAssume we have an array that contains tuples of students:\n\nstudents = [(\"andrej\", 20, 1.3),\n            (\"igor\", 22, 2.7),\n            (\"olga\", 21, 1.7)]\n\nThen, the following way we could sort on different criteria:\n\nselection_sort2(students, lambda x : x[0]) # sort w.r.t. names\nprint(students)\nselection_sort2(students, lambda x : x[1]) # sort w.r.t. age\nprint(students)\nselection_sort2(students, lambda x : x[2]) # sort w.r.t. grade\nprint(students)\n\n[('andrej', 20, 1.3), ('igor', 22, 2.7), ('olga', 21, 1.7)]\n[('andrej', 20, 1.3), ('olga', 21, 1.7), ('igor', 22, 2.7)]\n[('andrej', 20, 1.3), ('olga', 21, 1.7), ('igor', 22, 2.7)]\n\n\n\n\n\n\nStable sorting preserves the original order of elements with equal keys, which is especially useful when sorting complex objects.\n\nExample: Given a = [(\"Abel\", 20), (\"Babel\", 20), (\"Frey\", 19)], initially sorted by name, sorting again by age using sort(a, key=lambda x: x[1]) yields a = [(\"Frey\", 19), (\"Abel\", 20), (\"Babel\", 20)].\n\nThe idea behind stable sorting is that you can first sort by a secondary criterion (e.g., names), then by a primary one (e.g., grades), and the final result will retain the secondary order within groups that share the same primary key. Without stability, you’d need to re-sort each group manually.\n\n\n\n\ninsertion sort is stable\ninsertion sort is the fastest algorithm for small N.\nPrinciple:\n\nsorts from left to right.\ncreate a hole in the correct position for the element a[i]\n\n\n\ndef insertion_sort(a):\n    N = len(a)\n    # i = 1\n    # sorted(a[0..i-1])\n    for i in range(1, N):\n        k = i\n        while k &gt; 0:\n            if a[k] &lt; a[k - 1]: \n                a[k - 1], a[k] = a[k], a[k - 1]\n            else: break\n            k = k - 1\n\na = [1, -3, 4, 10, -99]\ninsertion_sort(a)\nprint(a)\n\n[-99, -3, 1, 4, 10]\n\n\n\n\nRuntime of insertion sort depends on whether the array was sorted before hand. (In selection sort run time is always the same formula)\n\nCase 1(Best Case): array is already sorted \\(\\Rightarrow \\mathcal{O}(n)\\) , since inner while loop always executes the break statement immediately.\nCase 2 (Worst case): array is reverse sorted \\(\\Rightarrow \\mathcal{O}(n^2)\\) , since each inner while loop always executes the whole range of \\(i\\)s.\nCase 3 (Average case): Array is randomly sorted, i.e. intuitively somewhere in between sorted and reversly sorted. In this case the inner while loop breaks after \\(\\frac{i}{2}\\). Then the complexity can be written as\n\\[T(N) = \\frac{c}{2}(1 + 2 + \\ldots + (N - 1)) \\in \\mathcal{O}(N^2)\\]\n\n\n\n\n\n\nfaster sorter algorithms that run in \\(\\mathcal{O}(N\\cdot\\log{N})\\) and \\(\\mathcal{O}(N)\\) (bucket sort).\nsuch algoriths are faster because they employ the “divide and conquer” principle (recursion):\n\ndivide the problem to smaller sub-problems and solve the smaller problems\ncombine the smaller solutions\n\ntwo classic exmples of such algorithms:\n\nmerge sort:\n\ndivide the array in two equal parts\nsorts the half errays\nmerge the sorted half arrays\n\nquick sort:\n\nchoose a pivot element\ndivide the array into “smaller than pivot” and “greater than pivot”\nsort the individual parts.",
    "crumbs": [
      "Weekly Summary",
      "Week 4"
    ]
  },
  {
    "objectID": "ss25/alda/sum/w04.html#vl-8---06.05.25",
    "href": "ss25/alda/sum/w04.html#vl-8---06.05.25",
    "title": "Week 4",
    "section": "VL 8 - 06.05.25",
    "text": "VL 8 - 06.05.25\n\nEfficient Sorting Algorithms (Cont.)\n\nfor small values, \\(N &lt; 30\\) insertion sort is the fastest algorithm\nfor larger \\(N\\) efficient sorting algorithms must be preffered: merge sort and quicksort (divide & conquer)\n\n\nMerge Sort\n\nDivide the array into two equal parts\nsort the half arrays\nmerge the sorted sub parts\n\n\ndef merge_sorted_arrays(l, r): # both l and r are sorted\n  a = [] # sorted array\n  i, k = 0, 0\n  Nl, Nr = len(l), len(r)\n  # a == merged(l[0:i], r[0:k]\n  while i &lt; Nl and k &lt; Nr: \n    if l[i] &lt;= r[k]: # &lt;= instead of &lt; so that sorting is stablef\n      a.append(l[i]) # append is efficient\n      i += 1\n    else:\n      a.append(r[k])\n      k += 1\n  a += l[i : Nl] # append rest of l\n  a += r[k : Nr] # append rest of r\n  return a\n\nl = [1, 3, 10, 11]\nr = [-1, 2, 20]\n\na = merge_sorted_arrays(l, r)\nprint(a)\n\n[-1, 1, 2, 3, 10, 11, 20]\n\n\nthe final step\na += l[i : Nl] # append rest of l\na += r[k : Nr] # append rest of r\nis enabled by the elegant python slicing syntax. The usual way without slicing would be:\nwhile i &lt; Nl:\n  a.append(l[i])\n  i += 1\nwhile k &lt; Nr:\n  a.append(r[k])\n  k += 1\nNow we define merge sort recursively as follows:\n\ndef merge_sort(a):\n  N = len(a)\n  if N &lt;= 1: return a\n  l = merge_sort(a[: N//2])\n  r = merge_sort(a[N//2:])\n  return merge_sorted_arrays(l, r)\n\na = list(range(20))\nrandom.shuffle(a)\nprint(a)\na = merge_sort(a)\nprint(a)\n\n[7, 19, 14, 18, 10, 9, 3, 16, 6, 15, 4, 5, 17, 13, 8, 11, 2, 0, 1, 12]\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n\n\n\nDisadvantage: Merge sort is not in-place \\(\\Rightarrow\\) extra memory is necessary for each merge sort call\nAdvantage: Merge sort is efficient and stable\n\n\nRun-time Analysis of Merge Sort\nRuntime of merge sort satisfies the following formula both in worst and best case:\n\\[\\begin{align*}\n&T(0 || 1) = c_1 \\\\\n&T(N) = c_2 + 2\\cdot T(\\frac{N}{2}) + c_3N\n\\end{align*}\\]\nTODO: tldr diagram and solution of the recurrence relation.\n\n\n\nQuicksort\n\nIn practice somewhat faster than merge sort (with a good choice of pivot)\nnot stable but in place.\nidea:\n\nchoose an element of the array as “pivot”. (naiv, better is to choose pivot randomly)\npartition the array: (incomplete sorting)\n\npivot is at the final position.\nall elements &lt;= pivot are left to the pivot\nall elements &gt; pivot are right the pivot\nthe left and right portions are not sorted\n\ncall quicksort recursively on the left and right partitions (divide and conquer)\n\n\nfirst we define the paritioning function:\n\ndef partition(a, l, r):  # l, r are left and right boundaries (inclusive) of a\n  pivot = a[r] # naive choice: Pivot\n  i = l\n  k = r - 1\n  while True:\n    while i &lt; r and a[i] &lt;= pivot: i += 1 # increment until found a misplaced element\n    while k &gt; l and a[k] &gt;= pivot: k -= 1 # decrement until found a misplaced element\n    if i &lt; k : a[i], a[k] = a[k], a[i]\n    else : break\n  a[i], a[r] = a[r], a[i] # bring pivot to the correct position\n  return i # so that recursive calls now where the partitions are\n\nnext we define\n\ndef quick_sort_impl(a, l, r):\n  if r &lt;= l: return # no return argument since in-place\n  i = partition(a, l, r)\n  quick_sort_impl(a, l, i-1)\n  quick_sort_impl(a, i+1, r)\n\nfinally we define a wrapper function as an interface for the user:\n\ndef quick_sort(a):\n  quick_sort_impl(a, 0, len(a) - 1)\n\na = list(range(20))\nrandom.shuffle(a)\nprint(a)\nquick_sort(a)\nprint(a)\n\n[16, 10, 3, 6, 1, 19, 12, 18, 13, 15, 14, 7, 2, 17, 9, 5, 4, 8, 0, 11]\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n\n\nWhy choosing pivot as the first element is naive?\n\nif pivot always stays on the first position \\(\\Rightarrow\\) \\(N^2\\). This happens if the arrray is already sorted (TODO: understand thus)\na naive solution: shuffle the array before sorting (of course doesn’t make much sense) \\(\\Rightarrow\\) uquivalently: choose the pivot randomly each time.\nimport random\np = random.randint(l, r) \na[p], a[r] = a[r], a[p] # replace right-most element with this random element\npivot = a[r]",
    "crumbs": [
      "Weekly Summary",
      "Week 4"
    ]
  },
  {
    "objectID": "ss25/alda/sum/w02.html",
    "href": "ss25/alda/sum/w02.html",
    "title": "Week 2",
    "section": "",
    "text": "review of previous lecture: data-structure triangle\nfor ADTs there’s lot’s of wiggle room for the concrete representation (the concrete bit sequences)\n\nexample: integers\n\n“unsigned” or “signed”\nthe number of allocated bits: uint8, int8 =&gt; uint16, int16 =&gt; uint32, int32 =&gt; uint64, int64 =&gt; infinite precision (python) (faster =&gt; slower). Python automatically switches to infinite precision if the numbers get too large.\n\nsmaller number of bits =&gt; overflow:\n\noverflow in uint8:\n\n\\(255_D = 1111,1111_B\\)\n\\(255_D + 1_D = 256_D = 1,0000,0000_B\\)\n\nHow to react to this? Solutions:\n\nIncrease the number of bits dynamically (python): not practical because not easy to implement in hardware.\nError warning: not practical because way too frequent.\nDon’t do anything: e.g.: \\(255_D + 1_D = 255_D\\): Associativity doesn’t hold anymore \\(255_D + (1_D - 1_D) = 255_D \\neq 254_D =\n255_D - 1_D = (255_D + 1_D) - 1_D\\)\n(Cyclical) Modulo arithmetic, k bits =&gt; modulo-\\(2^k\\) (% in python):\n\\(255_D + 1_D = 0_D\\)\nadvantages:\n\nvery efficient in hardware =&gt; simply perform the operations where the overflow is ignored\nalgebraic laws of basic operations still hold: associativity and commutativity\n\n\n\n\n\n\n\n\n\nElementary operations are ones that are defined for all data types:\n\nconstructor:\n\n\ncreate a new instance of a data type & allocate memory to it\nthe memory is initialized to a valid initial state. (otherwise we can’t be sure if operations performed on this object will deliver correct results)\nin python the constructor has the same name as the data type:\n\n\ni = int(); f = float(); a = list()\ni2 = int(7); f2 = float(10); b = [1, 2]\nprint(\"i:\", i, \"f:\", f, \"a: \", a)\nprint(\"i2:\", i2, \"f2:\", f2, \"b: \", b)\n\ni: 0 f: 0.0 a:  []\ni2: 7 f2: 10.0 b:  [1, 2]\n\n\nconstructors for custom-data types (classes): the function __init__(self, ...) has to be implemented.\n\n\n\ndestructor: deallocating the memory\ncomparison operator (==). Two different equalities:\n\nequal: same value / contents\nidentical: same object in the memory\ncomparing the identity of objects with id() or with is\n\na = [1, 2]\nb = [1, 2]\nc = b\nprint(\"1:\", id(a) == id(b))\nprint(\"2:\", id(c) == id(b))\nprint(\"3:\", a == b)\nprint(\"4:\", id(c) == id(b))\nprint(\"5:\", c == b and c == a)\n\nprint(\"6:\", a is b or a is c)\nprint(\"7:\", c is b)\n\n1: False\n2: True\n3: True\n4: True\n5: True\n6: False\n7: True\n\n\nc and b refer to the same memory location, different from the location of a. all of a, b, c have equal values; [1, 2].\nconsequense: value-semantics vs reference-semantics (see below)\n\n\n\n\nAnalogy: Accessing a website:\n\nvalue-semantics: store a copy of website.\n\nadvantage: we have control over the contents of the copy\ndisadvantage: possibly out-of-date.\n\nreference-semantics: store the URL of the website\n\nadvantage: always up-to-date\ndisadvantage: no control over the content; possibly deleted.\n\n\nWhat does it mean for programming languages, specifically for python:\n\nvalue-semantics: data is copied and stored at another location (== is True and is is False)\nreference-semantics: two varibles refer to the same location (both == and is are True)\nIn python all assignments use reference semantics, and in general python uses reference semantics\n\nExample\n\na = [1, 2]\nb = a\na[0] = -1\nprint(\"1:\", a, b);\nprint(\"2:\", a is b)\n\n1: [-1, 2] [-1, 2]\n2: True\n\n\nif we want to create another list object with a different identity but same value as a we use .copy() operator:\n\na = [1, 2]\nb = a.copy()\nprint(\"1:\", a == b)\nprint(\"2:\", a is b)\nb[0] = -1\nprint(\"3:\", a, b)\n\n1: True\n2: False\n3: [1, 2] [-1, 2]\n\n\nElementary data-types like numbers or booleans are immutable by default, which gives the ‘illusion’ of reference semantics.\n\na = 1\nb = a\nprint(\"1:\", a is b)\nprint(\"2:\", a == b)\nprint(\"3:\", a, b)\na = 2\nprint(\"4:\", a is b)\nprint(\"5:\", a == b)\nprint(\"6:\", a, b)\n\n1: True\n2: True\n3: 1 1\n4: False\n5: False\n6: 2 1",
    "crumbs": [
      "Weekly Summary",
      "Week 2"
    ]
  },
  {
    "objectID": "ss25/alda/sum/w02.html#vl-3---22.04.2025",
    "href": "ss25/alda/sum/w02.html#vl-3---22.04.2025",
    "title": "Week 2",
    "section": "",
    "text": "review of previous lecture: data-structure triangle\nfor ADTs there’s lot’s of wiggle room for the concrete representation (the concrete bit sequences)\n\nexample: integers\n\n“unsigned” or “signed”\nthe number of allocated bits: uint8, int8 =&gt; uint16, int16 =&gt; uint32, int32 =&gt; uint64, int64 =&gt; infinite precision (python) (faster =&gt; slower). Python automatically switches to infinite precision if the numbers get too large.\n\nsmaller number of bits =&gt; overflow:\n\noverflow in uint8:\n\n\\(255_D = 1111,1111_B\\)\n\\(255_D + 1_D = 256_D = 1,0000,0000_B\\)\n\nHow to react to this? Solutions:\n\nIncrease the number of bits dynamically (python): not practical because not easy to implement in hardware.\nError warning: not practical because way too frequent.\nDon’t do anything: e.g.: \\(255_D + 1_D = 255_D\\): Associativity doesn’t hold anymore \\(255_D + (1_D - 1_D) = 255_D \\neq 254_D =\n255_D - 1_D = (255_D + 1_D) - 1_D\\)\n(Cyclical) Modulo arithmetic, k bits =&gt; modulo-\\(2^k\\) (% in python):\n\\(255_D + 1_D = 0_D\\)\nadvantages:\n\nvery efficient in hardware =&gt; simply perform the operations where the overflow is ignored\nalgebraic laws of basic operations still hold: associativity and commutativity\n\n\n\n\n\n\n\n\n\nElementary operations are ones that are defined for all data types:\n\nconstructor:\n\n\ncreate a new instance of a data type & allocate memory to it\nthe memory is initialized to a valid initial state. (otherwise we can’t be sure if operations performed on this object will deliver correct results)\nin python the constructor has the same name as the data type:\n\n\ni = int(); f = float(); a = list()\ni2 = int(7); f2 = float(10); b = [1, 2]\nprint(\"i:\", i, \"f:\", f, \"a: \", a)\nprint(\"i2:\", i2, \"f2:\", f2, \"b: \", b)\n\ni: 0 f: 0.0 a:  []\ni2: 7 f2: 10.0 b:  [1, 2]\n\n\nconstructors for custom-data types (classes): the function __init__(self, ...) has to be implemented.\n\n\n\ndestructor: deallocating the memory\ncomparison operator (==). Two different equalities:\n\nequal: same value / contents\nidentical: same object in the memory\ncomparing the identity of objects with id() or with is\n\na = [1, 2]\nb = [1, 2]\nc = b\nprint(\"1:\", id(a) == id(b))\nprint(\"2:\", id(c) == id(b))\nprint(\"3:\", a == b)\nprint(\"4:\", id(c) == id(b))\nprint(\"5:\", c == b and c == a)\n\nprint(\"6:\", a is b or a is c)\nprint(\"7:\", c is b)\n\n1: False\n2: True\n3: True\n4: True\n5: True\n6: False\n7: True\n\n\nc and b refer to the same memory location, different from the location of a. all of a, b, c have equal values; [1, 2].\nconsequense: value-semantics vs reference-semantics (see below)\n\n\n\n\nAnalogy: Accessing a website:\n\nvalue-semantics: store a copy of website.\n\nadvantage: we have control over the contents of the copy\ndisadvantage: possibly out-of-date.\n\nreference-semantics: store the URL of the website\n\nadvantage: always up-to-date\ndisadvantage: no control over the content; possibly deleted.\n\n\nWhat does it mean for programming languages, specifically for python:\n\nvalue-semantics: data is copied and stored at another location (== is True and is is False)\nreference-semantics: two varibles refer to the same location (both == and is are True)\nIn python all assignments use reference semantics, and in general python uses reference semantics\n\nExample\n\na = [1, 2]\nb = a\na[0] = -1\nprint(\"1:\", a, b);\nprint(\"2:\", a is b)\n\n1: [-1, 2] [-1, 2]\n2: True\n\n\nif we want to create another list object with a different identity but same value as a we use .copy() operator:\n\na = [1, 2]\nb = a.copy()\nprint(\"1:\", a == b)\nprint(\"2:\", a is b)\nb[0] = -1\nprint(\"3:\", a, b)\n\n1: True\n2: False\n3: [1, 2] [-1, 2]\n\n\nElementary data-types like numbers or booleans are immutable by default, which gives the ‘illusion’ of reference semantics.\n\na = 1\nb = a\nprint(\"1:\", a is b)\nprint(\"2:\", a == b)\nprint(\"3:\", a, b)\na = 2\nprint(\"4:\", a is b)\nprint(\"5:\", a == b)\nprint(\"6:\", a, b)\n\n1: True\n2: True\n3: 1 1\n4: False\n5: False\n6: 2 1",
    "crumbs": [
      "Weekly Summary",
      "Week 2"
    ]
  },
  {
    "objectID": "ss25/alda/sum/w02.html#vl-4---24.04.2025",
    "href": "ss25/alda/sum/w02.html#vl-4---24.04.2025",
    "title": "Week 2",
    "section": "VL 4 - 24.04.2025",
    "text": "VL 4 - 24.04.2025\n\nContainers - Data types\n\nContainers contain other data.\nEfficient & systematic managmeent of large amounts of data\nEfficient repeated application of the same operation\nEfficient & simple querrying (seeking) of data\nData structures are constructed hierarchically in all programming languages. (composite) Ex.: hierachically composing new structures from simple (atomic) ones\n\nnatural numbers: atomic data type\n3 numbers: RGBValue\n1024 x 1024 RGBValue: Image\nSequence of Images: Video\n\n\n\nADT Array\nArray (list in python) is the most important / fundamental container data type:\n\nOperation (pseudocode): a = new_array(size, initial_value)\n\ninterpretation: create an array with size elements all of which initially have initial_value as value\naxioms:\n\nprecondition: -\npostcondition: len(a) == size and for all i in [0,..., size - 1]: get(a, i) == initial_value\n\npython:\n\na = list() # empty array with size == 0\nb = [3] * 10\nc = [-1, 2, 3, 'c']\nprint(a, b, c, sep=\"\\n\")\n\n[]\n[3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n[-1, 2, 3, 'c']\n\n\n\nOperation (pseudocode): k = len(a)\n\ninterpretation: number of elements in a\naxioms:\n\nprecondition:\npostcondition: k == size\n\npython:\n\na = [None] * 10\nlen(a)\n\n10\n\n\n\nOperation (pseudocode): v = get(a, i )\n\ninterpretation: get the element at the position i\naxioms:\n\nprecondition: 0 &lt;= i &lt;= size - 1 and v == element of a at position i\npostcondition: len(a) == size and for all i in [0,..., size - 1]: get(a, i) == initial_value\n\npython:\n\na = [1, 2, 3]\nv = a.__getitem__(2)\nv = a[2]\nprint(a)\n\n[1, 2, 3]\n\n\n\nOperation (pseudocode): set(a, i, v)\n\ninterpretation:\naxioms:\n\nprecondition: 0 &lt;= i &lt;= size - 1\npostcondition: get(a, i) == v\n\npython:\n\na = [-1, 2, 3]\na.__setitem__(1, 'c')\na[2] = 'd'\nprint(a)\n\n[-1, 'c', 'd']\n\n\n\nArrays store their elements consequtively =&gt; more efficient than other container types, since CPU’s process consecutive memeory cells faster.\npython allows i &lt; 0: -size &lt;= i &lt;= size - 1. Then:\n\nAxiom: i &lt; 0 =&gt; get(a, i) == get(a, len(a) - |i|)\n\n\nDyanmic arrays: here we simply give the operations\n\noperation: append(a, v)\npython: a.append(v) # efficient in pyton\noperation: append(a, other_array)\npython: a.extend(other_array) # efficient\noperation: insert(a, i, v) inserts and elements after position i\npython: a.insert(i) # less efficient\noperation: pop(a) (remove last eelment)\npython: a.pop() # efficient in python\noperation: remove(a, i) (remove the ith element)\npython: a.pop(i) or del a[i]\noperation: clear(a) delete everything\npython: a.clear() # now len(a) == 0\n\n\n\nAssociative Array\nAssociative arrays are called dictionary in python.\n\nMain idea of assoc. arrays is that they allow arbitrary data structures as index.\nEx.:\n\nImmatriculation number as index: students[1234567] =&gt; \"Alice Smith\"\nStrings as index, e.g. Name: `alda_grade[‘Bob Miller’]\nIn general: any data type that implements a hash function can be an nidex\n\nAssociative arrays are internally implemented as a dynamic array, where the index is computed by the hash function.\n\n\n\nStack\nIn python lists are automatically also stacks. (They can be used as stacks)\nonly the operations and python versions:\n\nOperation: top()\npython: s[-1]\n\nOperation: top()\npython: s[-1]\n\nOperation: pop()\npython: s.pop()\n\nOperation: push(s, v)\npython: s.append(v)",
    "crumbs": [
      "Weekly Summary",
      "Week 2"
    ]
  },
  {
    "objectID": "ss25/alda/sum/index.html",
    "href": "ss25/alda/sum/index.html",
    "title": "Weekly Summary",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nWeek 1\n\n\nApr 15, 2025\n\n\n\n\nWeek 2\n\n\nApr 22, 2025\n\n\n\n\nWeek 3\n\n\nApr 29, 2025\n\n\n\n\nWeek 4\n\n\nMay 6, 2025\n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Weekly Summary"
    ]
  },
  {
    "objectID": "ss24/time/index.html",
    "href": "ss24/time/index.html",
    "title": "Time Log",
    "section": "",
    "text": "calendar (with week numbers) pertaining to this semester:\nUsage: cal [general options] [-jy] [[month] year]\n       cal [general options] [-j] [-m month] [year]\n       ncal -C [general options] [-jy] [[month] year]\n       ncal -C [general options] [-j] [-m month] [year]\n       ncal [general options] [-bhJjpwySM] [-H yyyy-mm-dd] [-s country_code] [-W number of days] [[month] year]\n       ncal [general options] [-Jeo] [year]\nGeneral options: [-31] [-A months] [-B months] [-d yyyy-mm]\nTwo main tags:"
  },
  {
    "objectID": "ss24/time/index.html#weekly",
    "href": "ss24/time/index.html#weekly",
    "title": "Time Log",
    "section": "Weekly",
    "text": "Weekly\n\ntotal times:\n\n\n\n                 Total\n2024  Week 31   15h45m\n      Week 32   14h10m\n      Week 33    3h30m\n      Week 35    1h20m\n      Week 37    5h10m\n      Week 38    3h35m\n              ========\n                43h30m\n\n\n\nalgorithms and data structures (#alda) and oop for scientific computing (#sci-oop):\n\n\n\n                 Total                   Total\n2024  Week 31    7h40m  2024  Week 31     8h5m\n      Week 32   10h25m        Week 32    4h15m\n      Week 37    5h10m        Week 33    3h30m\n      Week 38    3h50m        Week 35    1h20m\n              ========                ========\n                 27h5m                  17h10m"
  },
  {
    "objectID": "ss24/time/index.html#daily",
    "href": "ss24/time/index.html#daily",
    "title": "Time Log",
    "section": "Daily",
    "text": "Daily\n\ntotal:\n\n\n\n                       Total\n2024 Jul    Tue 30.     5h5m\n            Wed 31.       5h\n     Aug    Thu  1.    4h10m\n            Fri  2.    1h30m\n            Mon  5.    2h30m\n            Tue  6.    5h35m\n            Wed  7.    3h25m\n            Thu  8.    2h40m\n            Tue 13.    1h35m\n            Wed 14.    1h55m\n            Mon 26.       1h\n            Tue 27.      20m\n     Sep    Tue 10.    2h30m\n            Fri 13.    2h40m\n            Mon 16.    3h35m\n                    ========\n                      43h30m\n\n\n\n#alda and #sci-oop side by side;\n\n\n\n                       Total                           Total\n2024 Jul    Tue 30.    1h15m    2024 Jul    Tue 30.    3h50m\n            Wed 31.       4h                Wed 31.       1h\n     Aug    Thu  1.    2h25m         Aug    Thu  1.    1h45m\n            Mon  5.    2h30m                Fri  2.    1h30m\n            Tue  6.    2h50m                Tue  6.    2h45m\n            Wed  7.    3h25m                Thu  8.    1h30m\n            Thu  8.    1h10m                Tue 13.    1h35m\n            Fri  9.      30m                Wed 14.    1h55m\n     Sep    Tue 10.    2h30m                Mon 26.       1h\n            Fri 13.    2h40m                Tue 27.      20m\n            Mon 16.    3h50m                        ========\n                    ========                          17h10m\n                       27h5m"
  },
  {
    "objectID": "ss24/time/index.html#entries",
    "href": "ss24/time/index.html#entries",
    "title": "Time Log",
    "section": "Entries",
    "text": "Entries\nTime log entries:\n\n\n\n2024-07-30 (6h!)\n#study #uni #exam\n    10:45 - 12:45 #sci-oop video reviews on moodle, Vid 1\n    -10m Break (#sci-oop)\n    14:00 - 15:45 #sci-oop video reviews on moodle, Vid 2\n    16:15 - 16:30 #sci-oop video reviews on moodle, Vid 2 \n        range based loops\n    16:30 - 17:45 #alda big #cpp sorting & serching\n\n2024-07-31 (6h!)\n#study #uni #exam\n    10:05 - 12:05 #alda big #cpp binary search ch 12\n    14:05 - 16:05 #alda big #cpp most frequent element ch 12\n        implemented most frequent element\n    16:35 - 17:35 #sci-oop move semantics ~ josuttis #cpp\n\n2024-08-01 (6h!)\n#study #uni #exam\n    10:35 - 13:15 #alda tutor notes, probleklausur\n    -15m Break (#alda)\n    14:45 - 16:45 #sci-oop move semantics ~ josuttis\n    -15m Break (#sci-oop)\n\n2024-08-02 (6h!)\n#study #uni #exam\n    10:45 - 12:45 #sci-oop move semantics ~ josuttis\n        finished ch 1.1\n    -30m Break (#sci-oop)\n\n2024-08-05 (6h!)\n#study #uni #exam\n    12:05 - 13:10 #alda big #cpp shell sort\n    -15m (#alda #cpp) Break\n    15:30 - 17:40 #alda big #cpp shell sort\n        implemented shell sort\n    -30m (#alda #cpp) Break\n\n2024-08-06\n    &lt;23:30 - 2:00 klog documentation\n    -45m Break & Distractions\n\n2024-08-06 (6h!)\n#study #uni #exam\n    9:45 - 11:15 #sci-oop move semantics \n        ch 1.2 - 1.5, 5p\n    11:35 - 12:50 #sci-oop move semantics ch 2\n        finished until summary chapter, 6p\n    14:45 - 15:35 #alda foundations of algorithms ~ neapolitan\n        preface & ch 1.0  \n    16:00 - 18:40 #alda foundations of algoroithms ~ neapolitan\n        ch 1.1 excluding matrix multiplication example\n    -40m #alda Break & Distractions\n\n2024-08-07 (5h30m!)\n#study #uni #exam\n    10:25 - 12:50 #alda foundations of algorithms ~ neapolitan\n        matrix multiplication example & ch 1.1\n        implemented & tested binary search\n    -20m #alda Break & Distractions\n    0m organized reading lists for ALDA and SCI-OOP \n        around 3.5 hours\n    18:00 - 19:20 #alda foundations of algorithms ~ neapolitan\n        ch1.2 fibonacci recursive and dynamic, impl and runtime\n\n2024-08-08 (4h!)\n#study #uni #exam\n    11:20 - 12:30 #alda implemented merge and mergesort\n        with proofs of correctness \n    0m sci-oop exam 14:20 - 16:00\n    17:00 - 18:30 #sci-oop typeset exam questions\n        and published them to the website\n\n2024-08-09\n    11:30 - 12:00 #alda typesetting first exam questions\n\n2024-08-13\n    10:10 - 12:05 quarto documentation, pdf options\n\n2024-08-13 (4h!)\n#study #uni #exam\n    12:25 - 13:20 #sci-oop josuttis #cpp move semantics\n        ch3.1 - Move semantics in ordinary classes \n    -10m Break #sci-oop #cpp\n    14:35 - 15:25 #sci-oop josuttis #cpp move semantics \n        ch3.2 - Implementing special copy/move member functions\n\n2024-08-13\n    19:15 - 20:15 #sports bodyshape fitness\n\n2024-08-14 (4h!)\n#study #uni #exam\n    10:45 - 12:55 #sci-oop josuttis #cpp move semantics \n        ch 3.3 - Special member functions\n    -15m Break #sci-oop #cpp\n\n2024-08-26 (3h30m!)\n#study #uni #exam\n    11:50 - 13:05 #sci-oop josuttis #cpp move semantics\n        revise ch 3\n    -15m Break #sci-oop #cpp\n\n2024-08-27 (3h!)\n#study #uni #exam\n    13:00 - 13:30 #sci-oop josuttis #cpp move semantics\n        ch 3.1.1 - \n    -10m Break #sci-oop #cpp\n\n2024-09-10 (5h!)\n#study #uni #exam\n    12:15 - 13:05 #alda gersting ch3 Recurrence\n        p. 157 - 159\n    15:30 - 17:30 #alda gersting ch3 recurrence relation\n        p. 159 - 163 until ex 7\n    -20m Break #alda\n\n2024-09-13 (4h!)\n#study #uni #exam\n    13:55 - 14:50 #alda gersting ch3 recurrence relations\n        p.163 - 165 \n    15:25 - 16:10 #alda gerstin ch3 recurrence relations\n        p.165 - 168 until Example 11\n    16:40 - 17:40 #alda \n        until p.169, implemented selection sort both iterative\n        and recursive versions\n\n2024-09-16 (4h!)\n#study #uni #exam\n    11:10 - 12:40 #alda gersting ch3 recurrence relations\n        p.169 - 171 implemented recursive & iterative binary search \n    -15m Break #alda\n    14:50 - 16:30 #alda gersting ch3 recurrence relations\n        p.171 - 171 Exercises 1, 2\n    -15m Break \n    17:00 - 17:55 #alda gersting ch3 recurrence relations\n        p.171 - 172 Exercises 2 - 12\n\n2024-09-20 (5h!)\n#self-study \n    10:35 - 13:30 #finance Beancount docs\n        command line accounting in context: custom scripting - end of chpater\n        finished chapter\n    -35m Break #finance \n    16:05 - 19:00 #finance Beancount docs\n        DE Counting Method Intro - types of accounts \n        read two chapters\n\n2024-09-24 (4h!)\n#self-study\n    12:10 - 13:40 #finance Beancount docs\n        DE Counting method: types of accounts - income statement\n    15:15 - 16:15 #finance Beancount docs\n        DE Counting method: clearing income - Balance Sheet \n    16:45 - 17:30 #finance Beancount docs\n        DE Coumting method: Summarizing - 17:30\n\n2024-09-30 (4h!)\n#self-study\n    11:45 - 12:45 #finance Beancount docs\n        DE Counting method: trial balance\n    15:15 - 16:00 #finance Beancount docs\n        DE Counting method: Balance Sheet\n    16:20 - 18:50 #finance Beancount docs\n        DE Counting method: Period Reporting - Chart of Accounts(excl)\n    -50m Break\n\n2024-10-01 (4h30m!)\n#self-study\n    10:25 - 11:40 Business and finance books glean\n    11:50 - 12:45 #finance Beancount docs\n        DE CM: Period reporting - plain-text accounting (excl)\n    14:10 - 14:40 #finance Beancount docs\n        DE CM: Plain-text accounting - the table perspective\n        Distracting a lot - gleaning productivity books"
  },
  {
    "objectID": "ss24/r/index.html",
    "href": "ss24/r/index.html",
    "title": "R Programming",
    "section": "",
    "text": "R Programming and its Applications to Stochastic",
    "crumbs": [
      "R Programming"
    ]
  },
  {
    "objectID": "ss24/r/index.html#section",
    "href": "ss24/r/index.html#section",
    "title": "R Programming",
    "section": "",
    "text": "weekly summary\nnotes\nsolutions",
    "crumbs": [
      "R Programming"
    ]
  },
  {
    "objectID": "ss24/oop/plan.html#reading-list",
    "href": "ss24/oop/plan.html#reading-list",
    "title": "Study Plan",
    "section": "Reading List",
    "text": "Reading List\n\nBasic, General, Intro:\n\nBig C++. Cay Horstmann\nProgramming Principles & Practice with C++. Stroustrup.\nA Tour of C++. Stroustrup\nC++ Crash Course. Josh Lospinoso\nC++ Primer. Lippmann\n\nModern, General, Scientific:\n\nDiscovering Modern C++ 2nd ed. Gottschild.\nModern C++ Programming Techniques for Scientific Computing - Lecture Notes. Ole Klein\n\nModern, Specific:\n\nFunctional Programming in C++. Cukic\nMove Semantics. Josuttis\nC++ Templates. Vandervoorde\nC++ STL. Josuttis\nOOP in C++. Josuttis"
  },
  {
    "objectID": "ss24/oop/exam1.html",
    "href": "ss24/oop/exam1.html",
    "title": "My Uni Notes",
    "section": "",
    "text": "OOP for Scientific Computing First Exam\npoints:\n\n\n\n1\n2\n3\n4\n5\n\\(\\Sigma\\)\n\n\n\n\n15\n20\n10\n10\n10\n65\n\n\n\nFollowing was asked in the exam:\n\nExplain following aspects of C++ :\n\nclass vs struct?\nnamespace. What is it, when & why is it used?\nprivate vs protected?\ncopy elision?\nheader guards. What, why?\nrule of five vs fule of zero?\ntemporaries? literals?\nhow does a shared pointer work?\nSFINAE?\nSOLID?\n\nShort code snippets were given and asked to explain & extend. With following topics:\n\ndefault function args\nconcepts\ntemplate parameters, default template parameters\nConstructor, copy constructor, copy assignment operator, move constructor, move assignment operator, overloaded constructor.\nLambda expression, functional programming\nCompile time branching\nCRTP\nInheritence. How to improve the given implementation\n\nHorner Schema: Variadic templates, recursion with templates(?), template metaprogramming\nAn incomplete implementation of an OOP system was given that was supposed to implement a simulation a prey-predator dynamic system, modeled by the Lotka-Volterra differential equations:\n\\[\\begin{align*}\n&\\frac{dx}{dt} = \\alpha x - \\beta xy, \\\\\n&\\frac{dy}{dt} = \\gamma y - \\delta xy\n\\end{align*}\\]\nThe incomplete OOP system had the following basic structure:\n\n\n\nLotka-Volterra OOP System\n\n\n\nImplement the PreyPredatorData Simulate(int steps, double dt) that creates a PreyPredatorData object, populates its members with the simulation data based on the Lotka-Volterra difference equations and returns the object:\n\n\\[\\begin{align*}\n&X_{n + 1} = X_n + \\Delta t (\\alpha x_n - \\beta x_ny_n) \\\\\n&Y_{n + 1} = Y_n + \\Delta t (\\delta x_ny_n- \\gamma y_n)\n\\end{align*}\\]\n\n?\n\n?"
  },
  {
    "objectID": "ss24/alda/sum.html",
    "href": "ss24/alda/sum.html",
    "title": "Weekly Summary",
    "section": "",
    "text": "date:\n\n\n\ndate:"
  },
  {
    "objectID": "ss24/alda/sum.html#week-1",
    "href": "ss24/alda/sum.html#week-1",
    "title": "Weekly Summary",
    "section": "",
    "text": "date:\n\n\n\ndate:"
  },
  {
    "objectID": "ss24/alda/sum.html#week-2",
    "href": "ss24/alda/sum.html#week-2",
    "title": "Weekly Summary",
    "section": "Week 2",
    "text": "Week 2\n\nLecture 1\ndate:\n\n\nLecture 2\ndate: 23/04/24\n\nfachschaft\n\nstapel\nkaffeklatsch\nLernraum - time & place tba (instagram, whatsapp groups)\nRoom: INF 205 Mathematikon\nwebsite\n\ncompiler explorer\nSmall assembly example; modern compilers are very clever at optimizing\nassertions, pre- and post conditions, invariants.\nfast power algorithm, it’s correctness proof\nrules for calculating time complexity of sequential programs\na common reccurence relation pattern that comes up often,\n\n\\[\\begin{align}\nR(n) &= a, &&\\text{if n = 1} \\\\\n     &= cn + d\\cdot R(n/b) &&\\text{if n &gt; 1, divide and conquer}\n\\end{align}\\]\n\ncomplexity of this reccurence relation and its proof\nIntro to Graphs, basic definitions"
  },
  {
    "objectID": "ss24/alda/sum.html#week-3",
    "href": "ss24/alda/sum.html#week-3",
    "title": "Weekly Summary",
    "section": "Week 3",
    "text": "Week 3\n\nLecture 1\ndate:\n\n\nLecture 2\ndate: 30/04/24\n\nsimply linked list\n\nsplicing\n\narrays\n\nassembly realization of array access via the website compiler explorer link with c++ and rust. Differences between c++ and rust.\nmemory allocation in c++ with alloc() and free()\ntime complexity of array memory allocation in c++ with alloc(): an experiment\npushBack() and popBack() for arrays\n\ntheir realization and complexity"
  },
  {
    "objectID": "ss24/alda/sum.html#week-4",
    "href": "ss24/alda/sum.html#week-4",
    "title": "Weekly Summary",
    "section": "Week 4",
    "text": "Week 4\n\nLecture 1\ndate: 6/5/24\n\nintroduction to amortized complexity\n\namortized complexity analysis of pushBack() and popBack() operations: both \\(\\mathcal{O}(1)\\)\n\nstacks and queues - introductory discussions\n\ndouble-ended queues\n\nring buffer implementation of a queue\nintroduction to hashing\n\n\n\nLecture 2\ndate: 07/05/24\n\ndivision by a constant is optimized by the compiler (this cannot be done for division by a variable)\nbook recommendation: Hacker’s Delight\nHashing:\n\nintro & some applications\nsome defs:\n\n\\(M \\subseteq T\\). \\(M\\): set of Elements of a certain type \\(T\\), that we want to store (or have stored) in a table and access via their keys.\n\\(m\\): number of memory slots.\n\\(|M|\\): total number of elements stored in the table.\n\\(\\text{key}: M\\rightarrow Key\\): Function that maps elements to their key values\n\\(Key = im(key) = key[M]\\): the set of key values (the range of the key function)\n\\(h: Key\\rightarrow [0, m)\\): the hashing function that maps key values to memory slots \\(0\\dots m - 1\\).\n\npefect hashing: if there are more memory slots than possible key values, \\(h\\) can map each key to a single slot \\(\\Rightarrow\\) over-optimistic, we don’t have so much memory, since usually \\(|Key|\\gg m\\) (Number of possible key values much greater than number of slots).\nimperfect hashing: \\(\\exists e_1, e_2\\in M\\) s.t. \\(e_1 \\neq e_2\\) but \\(h(key(e_1)) = h(key(e_2))\\). This is called collision.\nclosed hashing: an example for imperfect hashing , where the elements of the table are simply linked lists, supporting the operations:\n\ninsert(e). Insert en element \\(e\\in M\\)\nremove(k). Remove an element \\(e\\) whose key is \\(k\\), returning \\(e\\)\nfind(k): Find element \\(e\\) with the key k, return \\(e\\) if found.\nTime-complexities:\n\ninsert(e): \\(\\mathcal{O}(1)\\)\nremove(k): \\(\\mathcal{O}(\\text{List length})\\)\nfind(k): \\(\\mathcal{O}(\\text{List length})\\)\nworst case: bad hash function that maps all keys to the same slot ! \\(\\Rightarrow \\mathcal{O}(|M|)\\)\n\nStochastic analysis of random hash functions & proofs of (with an introductory discussion of birthday paradox):\n\ntheorem: random hash function is likely to be perfect if \\(m \\in \\Omega(n^2)\\)\ntheorem: random hash functions lead to lists of length \\(\\mathcal{O}(1)\\), if \\(|M| \\in \\mathcal{O}(m)\\)"
  },
  {
    "objectID": "ss24/alda/sum.html#week-5",
    "href": "ss24/alda/sum.html#week-5",
    "title": "Weekly Summary",
    "section": "Week 5",
    "text": "Week 5\n\nLecture 1\ndate: 13/5/24\n\nUniversal hashing functions: definition & Theorem 1 holds also for universal hashing functions\n\nA family of universal hashing functions, proof of theorem 1 for these functions\nanother example for a universal hashing function based on bit matrix multiplication\nexample: tabulation hashing\n\nopen hashing: a different way to resolve collisions, without using linked lists, instead looking for the next free table slot:\n\nadvantage: contigious address values \\(\\Rightarrow\\) less cache misses, faster.\nbounded linear probing:\n\ninsert & find algorithms, invariants.\nremove is more difficult \\(\\Rightarrow\\) its implementation.\n\n\nintro to sorting\n\nintro to insertion sort.\n\n\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/alda/sum.html#week-6",
    "href": "ss24/alda/sum.html#week-6",
    "title": "Weekly Summary",
    "section": "Week 6",
    "text": "Week 6\n\nLecture 1\ndate: 20/05/24\n\nonline: Heap data structure\n\n\n\nLecture 2\ndate: 21/05/24\n\nprogramming example with compiler explorer: fibonacci iterative and recursive implementation, gcc optimization. (short detour: call stack) compiler can automatically implement tail recursion.\ninsertion algorithms:\n\ninsertion sort: pseudo-code implementation.\nmerge sort:\n\ndivide and conquer,\nmerging (\\(\\mathcal{O}(n))\\))\ntime-complexity of merge sort: assuming (without loss of generality) \\(n = 2^k\\) leads to master theorem. (wlog: we can extend a list to be \\(2^k\\))\n\n\\(\\Theta(n\\cdot\\log(n))\\) is the best we can do for comparison-based sorting\n\ndefinition of comparison-based sorting, fundamental operations\nany such algorithm must at least be able to differentiate between all \\(n!\\) permutations of the list \\(\\Rightarrow\\) lower-bound analysis via a comparison tree.\n\n\n\npartial integration\n\n\n\nquicksort: divide-and-conquer, but “reversed”\n\ncomplexity of quicksort (worst case is \\(\\mathcal{O}(n^2))\\)\nPivot is always the median \\(\\Rightarrow\\) \\(\\mathcal{O}(n\\cdot\\log{n})\\)\nproblem: finding the median (a good pivot) is not easy.\ncomplexity-analysis:"
  },
  {
    "objectID": "ss24/alda/sum.html#week-7",
    "href": "ss24/alda/sum.html#week-7",
    "title": "Weekly Summary",
    "section": "Week 7",
    "text": "Week 7\n\nLecture 1\ndate: 27/05/24\n\n\n\n\n\nLecture 2\ndate: 28/05/24\n\nexample: the c++ compiler optimizes calculation of middle value by generating assembly for r + (r - l) / 2 instead of (l + r) / 2, in order to reduce chance of overflow.\nquicksort with tail-recursion to reduce stack depth (revisiion of the previous lecture)\nquickselect algorithm from quicksort: can be used to determine the median of a sequence in \\(\\mathcal{O}(n)\\).\nsorting faster than \\(\\mathcal{\\Omega}(n\\log(n))\\) (without comparisons):\n\nKSort (Bucketsort), array implementation of bucketsort (in-place).\n\\(K^d\\) Sort: Least Significant Digit Radix Sorting.\n\nbinary search\n\nintermezzo: insertion sort in \\(\\mathcal{O}(\\log(n)\\cdot n)\\): library sort link"
  },
  {
    "objectID": "ss24/alda/sum.html#week-8",
    "href": "ss24/alda/sum.html#week-8",
    "title": "Weekly Summary",
    "section": "Week 8",
    "text": "Week 8\n\nLecture 1\ndate:\n\n\nLecture 2\ndate: 06/04/24\n\nc++ unique pointer implementation and move semantics\n(a, b) Trees - inserting"
  },
  {
    "objectID": "ss24/alda/sum.html#week-1-1",
    "href": "ss24/alda/sum.html#week-1-1",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/alda/sum.html#week-1-2",
    "href": "ss24/alda/sum.html#week-1-2",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/alda/sum.html#week-1-3",
    "href": "ss24/alda/sum.html#week-1-3",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/alda/sum.html#week-1-4",
    "href": "ss24/alda/sum.html#week-1-4",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/alda/sum.html#week-1-5",
    "href": "ss24/alda/sum.html#week-1-5",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/alda/sum.html#week-1-6",
    "href": "ss24/alda/sum.html#week-1-6",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/alda/sum.html#week-1-7",
    "href": "ss24/alda/sum.html#week-1-7",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/alda/index.html",
    "href": "ss24/alda/index.html",
    "title": "Alda",
    "section": "",
    "text": "Algorithms and Data Structures",
    "crumbs": [
      "Alda"
    ]
  },
  {
    "objectID": "ss24/alda/index.html#section",
    "href": "ss24/alda/index.html#section",
    "title": "Alda",
    "section": "",
    "text": "weekly summary\nnotes\nsolutions\nplan\nexam",
    "crumbs": [
      "Alda"
    ]
  },
  {
    "objectID": "plan.html",
    "href": "plan.html",
    "title": "Plan",
    "section": "",
    "text": "Pflicht (total = 54LP)\n\nAlda 8LP\nIBN 8LP\nISW 8LP\nBS (4LP + 2UK) 6LP\nFP 8LP\nBA 12LP\nBK 4LP\n\nWM (total = 22LP)\n\nWM-I 8LP\nWM-II 8LP\nWM-III 6LP\n\nFUK (total = 4LP)\n\nFUK-I (2UK) 2LP\nFUK-II (2UK) 2LP\n\nAG (total: 8LP)\n\nTheoPhys-II 8LP\n\n\nsum total: 88LP\nprogress: 92/180 \\(\\approx\\) 51%\n\n\nVersion 1\n\nSS 24 (total: 16LP)\n\nAlda 8LP\nWM-I 6LP\nFUK-I (2UK) 2LP\n\nWS 24/25 (total: 18LP)\n\nISW 8LP\nWM-II 8LP\nFUK-II (2UK) 2LP\n\nSS 25 (total: 24LP)\n\nFP 8LP\nIBN 8LP\nAG: TheoPhys-II 8LP\n\nWS 25/26 (total: 14LP)\n\nWM-III 8LP\nBS 6LP\n\nSS 26 (total: 16LP)\n\nBA 12LP\nBK 4LP"
  },
  {
    "objectID": "plan.html#to-do-as-of-ss-24",
    "href": "plan.html#to-do-as-of-ss-24",
    "title": "Plan",
    "section": "",
    "text": "Pflicht (total = 54LP)\n\nAlda 8LP\nIBN 8LP\nISW 8LP\nBS (4LP + 2UK) 6LP\nFP 8LP\nBA 12LP\nBK 4LP\n\nWM (total = 22LP)\n\nWM-I 8LP\nWM-II 8LP\nWM-III 6LP\n\nFUK (total = 4LP)\n\nFUK-I (2UK) 2LP\nFUK-II (2UK) 2LP\n\nAG (total: 8LP)\n\nTheoPhys-II 8LP\n\n\nsum total: 88LP\nprogress: 92/180 \\(\\approx\\) 51%\n\n\nVersion 1\n\nSS 24 (total: 16LP)\n\nAlda 8LP\nWM-I 6LP\nFUK-I (2UK) 2LP\n\nWS 24/25 (total: 18LP)\n\nISW 8LP\nWM-II 8LP\nFUK-II (2UK) 2LP\n\nSS 25 (total: 24LP)\n\nFP 8LP\nIBN 8LP\nAG: TheoPhys-II 8LP\n\nWS 25/26 (total: 14LP)\n\nWM-III 8LP\nBS 6LP\n\nSS 26 (total: 16LP)\n\nBA 12LP\nBK 4LP"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "My uni notes & resources"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Uni Notes",
    "section": "",
    "text": "Plan"
  },
  {
    "objectID": "index.html#semesters",
    "href": "index.html#semesters",
    "title": "Uni Notes",
    "section": "Semesters",
    "text": "Semesters\n\nWS 23/24\nSS 24\nWS 24/25\nSS 25"
  },
  {
    "objectID": "ss24/alda/exam1.html",
    "href": "ss24/alda/exam1.html",
    "title": "My Uni Notes",
    "section": "",
    "text": "what was asked on the exam:\n\nAdjacency Matrix \\(A\\) of a graph \\(G\\):\n\nwrite the pseudocode for an optimal algorithm that determines the total number of nodes in the graph with equal in- and out-degrees.\nAnalyze the complexity of your algorithm and prove optimality\n\nHeaps\nHashing\n\nOpen hashing. Insert a sequence of elements\nOpen hashing. Delete a sequence of elements\n\nStandard questions for comparing functions asymptotically, determining growth rate of reccurence relations with and without applications of the master theorem, analyzing complexity of short pseudocode algorithms like\nread(t)\nk := 1\ni : = 1\nwhile (k &lt;= t) :\n    i := i + 1\n    k := k + i\nShort proofs of statements regarding (a, b) trees and graphs\nSimple proof by induction problem\nDijkstra shortest path algorithm\n\nwasn’t asked:\n\nsorting\nproblems specifically for divide & conquer / recursion\nproblems specifically for dynamic programming\nlinear programming\napproximation / heuristic algorithms\nalgorithms on strings"
  },
  {
    "objectID": "ss24/alda/exam1.html#alda-sose-24-1st-exam",
    "href": "ss24/alda/exam1.html#alda-sose-24-1st-exam",
    "title": "My Uni Notes",
    "section": "",
    "text": "what was asked on the exam:\n\nAdjacency Matrix \\(A\\) of a graph \\(G\\):\n\nwrite the pseudocode for an optimal algorithm that determines the total number of nodes in the graph with equal in- and out-degrees.\nAnalyze the complexity of your algorithm and prove optimality\n\nHeaps\nHashing\n\nOpen hashing. Insert a sequence of elements\nOpen hashing. Delete a sequence of elements\n\nStandard questions for comparing functions asymptotically, determining growth rate of reccurence relations with and without applications of the master theorem, analyzing complexity of short pseudocode algorithms like\nread(t)\nk := 1\ni : = 1\nwhile (k &lt;= t) :\n    i := i + 1\n    k := k + i\nShort proofs of statements regarding (a, b) trees and graphs\nSimple proof by induction problem\nDijkstra shortest path algorithm\n\nwasn’t asked:\n\nsorting\nproblems specifically for divide & conquer / recursion\nproblems specifically for dynamic programming\nlinear programming\napproximation / heuristic algorithms\nalgorithms on strings"
  },
  {
    "objectID": "ss24/alda/plan.html#reading-list",
    "href": "ss24/alda/plan.html#reading-list",
    "title": "Study Plan",
    "section": "Reading List",
    "text": "Reading List\n\nAlgorithms\n\nBasic:\n\nUnderstanding Algorithms. Brunskill\nAlgorithms Unlocked. Cormen\nFirst Course in Algorithms Through Puzzles. Ryuhei Uehara\nAlgorithmic Thinking. Daniel Zingaro\nPrincipes of Algorithmic Problem Solving. Johan Sannemo\nGrokking Algorithms. Aditya Bhargava\n\nIntermediate:\n\nDesign and Analysis of Algorithms. Jeffrey Smith\nAlgorithms. Jeff Erickson\nHow to Think About Algorithms. Jeff Edmonds\nProblems on Algorithmics. Ian Perberry\nFundamentals of Algorithmics. Brassard, Bratley.\nAlgorithmen & Datenstrukturen - Grundwerkzeuge. Kurt Melhorn\nLecture Notes on Algorithms. Ian Perberry\nAlgorithm Design. Kleinberg, Tardos\nAlgorithms Illuminated. Roughgarden\nCompared to What. G. J. E. Rawlins\nFoundations of Algorithms. Richard Neapolitan\nData Structurese & Their Algorithms. Harry Lewis, Larry Denenberg\nAlgorithms + Data Structures = Programs. Niklaus Wirth\nAlgorithms and Data Structures - Design, Correctness, Analysis. Jeffrey H. Kingston\nComputer Algorithms. Baase\n\nC++:\n\nData Structures & Problem Solving Using C++. M. A. Weiss\nData Structures & Algorithm Analysis in C++. M. A. Weiss\nData & Algorithms in C++. Drozdek.\nData Structures other Objects using C++. Walter Savitch\nPrinciples of Algorithmic Problem Solving. Johan Sannemo\nGuide to Competitive Programming. Antti Laaksonen\n\nC:\n\nAlgorithms and Data Structures - An Approach in C. Bowman\nFoundations of Computer Science. Aho, Ullman\nPrograms and Datastructures in C. Ameraal\n\nPython:\n\nData Structures and Algorithms Using Python. Rance D. Necaise.\nData Structures & Algorithms in Python. Canning, Broder, Lafore\nCompetitive Programaming with Python. Duerr, Vie\nProblem Solving with Algorithms and Data Structures Using Python. Franklin, Beedle\n\n\n\n\nGraph Theory and Discrete Mathematics\n\nGeneral Discrete Mathematics:\n\nMathematical Structures for Computer Science. Judith Gersting\nDiscrete & Combinatorial Mathematics. Grimaldi\nConcrete Mathematics Knuth\nDiskerte Mathematik fuer Einsteiger. Beutelspacher\nDiscrete Mathematics in Computer Science. Golovnev, Kulikov\n\nGraph Theory Specific\n\nGraph Theory - A Poblem Oriented Approach. Daniel A. Marcus\nAlgorithmic Graph Theory. Alan M. Gibbons\nSets, Puzzles & Postmen. Higgins\n\n\nSpecifically:\n\nGersting:\n\n3: Recurrence relations & analysis of algorithms\n5: Graphs & Trees\n7: Graph algorithms\n\nRosen:\n\n3: Algorithms\n5: Induction & Recursion\n8: Advancerd Counting: recurrence relations\n10: Graphs\n11: Trees\n\nGrimaldi:\n\n4: Mathematical induction\n5.7, 5.8: Analysis of Algorithms\n10: Recurrence relations\n11, 12, 13: Graph Theory"
  },
  {
    "objectID": "ss24/index.html#courses",
    "href": "ss24/index.html#courses",
    "title": "SS 24",
    "section": "Courses",
    "text": "Courses\n\nAlda\nR\nOOP",
    "crumbs": [
      "Bachelor",
      "SS 24"
    ]
  },
  {
    "objectID": "ss24/index.html#time",
    "href": "ss24/index.html#time",
    "title": "SS 24",
    "section": "Time",
    "text": "Time\n\ntimes",
    "crumbs": [
      "Bachelor",
      "SS 24"
    ]
  },
  {
    "objectID": "ss24/oop/index.html",
    "href": "ss24/oop/index.html",
    "title": "OOP Sci",
    "section": "",
    "text": "Object Oriented Programming for Scientific Computing",
    "crumbs": [
      "OOP Sci"
    ]
  },
  {
    "objectID": "ss24/oop/index.html#section",
    "href": "ss24/oop/index.html#section",
    "title": "OOP Sci",
    "section": "",
    "text": "weekly summary\nnotes\nsol\nplan\nexam",
    "crumbs": [
      "OOP Sci"
    ]
  },
  {
    "objectID": "ss24/oop/sum.html",
    "href": "ss24/oop/sum.html",
    "title": "Weekly Summary",
    "section": "",
    "text": "date:\n\n\n\ndate:"
  },
  {
    "objectID": "ss24/oop/sum.html#week-1",
    "href": "ss24/oop/sum.html#week-1",
    "title": "Weekly Summary",
    "section": "",
    "text": "date:\n\n\n\ndate:"
  },
  {
    "objectID": "ss24/oop/sum.html#week-2",
    "href": "ss24/oop/sum.html#week-2",
    "title": "Weekly Summary",
    "section": "Week 2",
    "text": "Week 2\n\nLecture 1\ndate:\n\n\nLecture 2\ndate: 25/4/24\n\nslides: 27 -\ntesting with googletests\n\ngoogletests has to be cloned into the project as a submodule and build together with your code.\n\ntemplates\ntemplate templates\nrenaming types with typedef\nclasses and structs\n\nessentially the same thing, only difference being the default visibility: public for struct.\naccess specifiers: private, public, protected\nfriend class\nconstructors (they are a little messy in c++ due to legacy code issues)\n\nmove constructor:\nconverting constructors (implicit type conversions) \\(\\rightarrow\\) hard to find bugs.\nexplicit keyword.\nconversion operators.\ndelegating constructors.\n\ndestructors \\(\\rightarrow\\) RAII (resource acquisition if initialization)\nthe rule of zero or five.\nmutable members\nthe singleton pattern (single source of truth)"
  },
  {
    "objectID": "ss24/oop/sum.html#week-3",
    "href": "ss24/oop/sum.html#week-3",
    "title": "Weekly Summary",
    "section": "Week 3",
    "text": "Week 3\n\nLecture 1\ndate: 29/04/24 - Monday\n\nbasic cmake concepts\nSheet 2 execises discussion\n\nbasic googletest inclusion - slides are sufficient\n\npresentation proposal should have a presentation date.\n\n\n\nLecture 2\ndate: 02/05/24 - Thursday\n\nslides: 02 - standard\nreview of past lecture:\n\ntemplates\ntypedef\nclasses & structs\nconstructors\ndestructors: deep copy\n\nfundamental concepts of c++: inheritence\n\nlittle inheritence example\ndeadly diamond of death\ncomposition over inheritence\npublic vs private/protected inheritence\nis-a vs has-a\nSOLID principles\n\ndiscussion of the Liskov Subtitution Principle (LSP)\n\n\nproject structure\n\nheader files, header guards\nsource files separate from headers (templates go against this)\nnamespaces to structure and prevent name clashes\n\nc++ standard library:\n\noverview\nstandard input/output, standard error\ncontainers and companion classes\n\nsequences \\(\\approx\\) arrays: array, vector, deque, list, forward list\ncontainer adaptors stack, queue, priority queue\nassociative containers \\(\\approx\\) hash map: set, multiset, map, multimap\nunsorted associative containers: unordered set/multiset/map/multimap\n\niterators: generalization of pointer concept, they can be dereferenced and advanced to show to the subsequent element\nalgorithms: tailored to dfferent iterator categories, make full use of the capabilities of the container.\n\nfunctional programming examples\n\n\nError Handling:\n\nassert: Run-time sanity check\nstatic_assert: compile check with a similar purpose for template meta programming\nexception: error handling mechanism for situation that should not be the norm\n\ndiscussion of exceptions"
  },
  {
    "objectID": "ss24/oop/sum.html#week-4",
    "href": "ss24/oop/sum.html#week-4",
    "title": "Weekly Summary",
    "section": "Week 4",
    "text": "Week 4\n\nLecture 1\ndate: 06/05/24\n\nslides: 03 - advanced\nInheritence & dynamic polymorphism further discussions.\npolymorphism\n\nstatic polymorphism \\(\\approx\\) early binding\ndynamic polymorphism \\(\\approx\\) late binding\nsimple c++ illustration with the keyword virtual, references etc…\n\nc++ implementation of dynamic polymorphism using vtables (dispatch tables).\ncost of polymorphism\ncopying polymorphic types\n\nabstract base class (with a pure vitual function)\nfactory pattern (it is a creational pattern)\n\n\n\nLecture 2\ndate:\nholiday"
  },
  {
    "objectID": "ss24/oop/sum.html#week-5",
    "href": "ss24/oop/sum.html#week-5",
    "title": "Weekly Summary",
    "section": "Week 5",
    "text": "Week 5\n\nLecture 1\ndate: 13/5/24\n\nsolutions to the exercise sheet 2\npresentations:\n\ngit branches & tags\nIDE’s\nvalgrind\n\n\n\n\nLecture 2\ndate: 16/5/24\n\nc++ 11 features: (slide 95)\n\nautomatic type deduction\ntrailing return type\nmove semantics. Before c++ 11 there were two types of variables:\n\nvalues: assignment creates a new independent entity\nreferences and pointers: assignment creates and alias\ncopy constructor:\n\ndeep copy \\(\\Rightarrow\\) value semantics\nshallow copy \\(\\Rightarrow\\) reference semantics\n\nc++ 11: third type of semantics: move semantics\nforwarding references are not\n\nsmart pointers\n\nunique pointers: unique_ptr\nshared pointers: shared_ptr\nweak pointers (non-owning): weak_ptr\nraw pointer usage should be avoided\nso basically in modern c++ two types of pointers\n\nowning pointers: unique_ptr, shared_ptr\nnon-owning pointers: weak_ptr\n\npitfalls:\n\nlambda expressions & closures: generalization of functors in c++\n\ncurrying: \\((\\mathbb{N} \\times \\mathbb{N}) \\rightarrow \\mathbb{N} \\equiv \\mathbb{N} \\rightarrow (\\mathbb{N} \\rightarrow \\mathbb{N})\\)\nbuilder pattern with lambda functions\n\nrandom number generators\ntime measurement (slide 123)"
  },
  {
    "objectID": "ss24/oop/sum.html#week-6",
    "href": "ss24/oop/sum.html#week-6",
    "title": "Weekly Summary",
    "section": "Week 6",
    "text": "Week 6\n\nLecture 1\ndate: 20/05/24\n\nholiday\n\n\n\nLecture 2\ndate: 23/05/24\n\nsolutions & presentations"
  },
  {
    "objectID": "ss24/oop/sum.html#week-7",
    "href": "ss24/oop/sum.html#week-7",
    "title": "Weekly Summary",
    "section": "Week 7",
    "text": "Week 7\n\nLecture 1\ndate: 05/27/24\n\nreview of c++ 11 features from previews lectures:\n\nauto keyword: when to use it.\nmove constructors and move assignment\nshared pointers, weak pointers, unique pointers.\nlambda expressions, functors.\nrandom number generators\n\nrange based loops\nadvanced topics:\n\ninheritance and dynamic polymorphism\nresource acquisition is initialization (RAII)\ntemplate specialization:\n\nfunction template specialization, vs\nclass template specialization\n\ntemplates vs inheritance\n\nachieving the same effect as dynamic polymorphism with static polymorphisdm \\(\\Rightarrow\\) CRTP (curiously recurring template pattern)\n\n\n\n\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/oop/sum.html#week-1-1",
    "href": "ss24/oop/sum.html#week-1-1",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/oop/sum.html#week-1-2",
    "href": "ss24/oop/sum.html#week-1-2",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/oop/sum.html#week-1-3",
    "href": "ss24/oop/sum.html#week-1-3",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/oop/sum.html#week-1-4",
    "href": "ss24/oop/sum.html#week-1-4",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/oop/sum.html#week-1-5",
    "href": "ss24/oop/sum.html#week-1-5",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/oop/sum.html#week-1-6",
    "href": "ss24/oop/sum.html#week-1-6",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/oop/sum.html#week-1-7",
    "href": "ss24/oop/sum.html#week-1-7",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/oop/sum.html#week-1-8",
    "href": "ss24/oop/sum.html#week-1-8",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/r/sum.html",
    "href": "ss24/r/sum.html",
    "title": "Weekly Summary",
    "section": "",
    "text": "date:\n\n\n\ndate:"
  },
  {
    "objectID": "ss24/r/sum.html#week-1",
    "href": "ss24/r/sum.html#week-1",
    "title": "Weekly Summary",
    "section": "",
    "text": "date:\n\n\n\ndate:"
  },
  {
    "objectID": "ss24/r/sum.html#week-2",
    "href": "ss24/r/sum.html#week-2",
    "title": "Weekly Summary",
    "section": "Week 2",
    "text": "Week 2\n\nLecture 1\ndate: 22/4/24\n\nresources for R\n\nadvanced R ~ hadley wickham link\nr graphics cookbook link\ntidyverse\n\npackages\n\ninstalling and removing packages, package dependencies; shiny, learnr\nnamespaces and name collisions;\ndatasets package for learning; mtcars, iris\n\nfunction return value and print side effect\nclearing variables with rm(x)\nplotting\n\nbasic data plotting with plot\nbasic function plotting with plot and curve\n\n\n\n\nLecture 2\ndate: 26/4/24\n\ncontent: moodle videos 3 & 4\nr is object oriented - everything is an object\n\nclass vs typeof (small difference)\n\nr is also functional: everything that happens is a function call\n\ndifference between functions and function calls sin vs sin()\n\natomic vectors vs lists\ntype casting\nzero length vectors\nmachine numbers (representation of real numbers in R)\nbig integers - r represents large integers instead of 2’s complement.\nvectors have no dimension, array has one dimension. vectors are not arrays.\nfor data-sets use data-frames like: tibbles, data tables…"
  },
  {
    "objectID": "ss24/r/sum.html#week-3",
    "href": "ss24/r/sum.html#week-3",
    "title": "Weekly Summary",
    "section": "Week 3",
    "text": "Week 3\n\nLecture 1\ndate:\n\n\nLecture 2\ndate: 03/05/24 - Fri\n\nnew features in R\n\nother constructs instead of for loops that are faster\nanonymous functions, lambda notation\ndiscrete probability distributions\nstrings as factors\n.class2 can show all classes to which an object belongs, including implicit classes.\n\nnew features in r 4.1\n\nfactor function behavior\nnative pipe operator, analogous to shell pipes, eliminating the need for magrittr pipes.\nas.vector() removes attributes from a vector, like component names.\ncolon operator precedence.\ntail recursion"
  },
  {
    "objectID": "ss24/r/sum.html#week-1-1",
    "href": "ss24/r/sum.html#week-1-1",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/r/sum.html#week-1-2",
    "href": "ss24/r/sum.html#week-1-2",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/r/sum.html#week-1-3",
    "href": "ss24/r/sum.html#week-1-3",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/r/sum.html#week-1-4",
    "href": "ss24/r/sum.html#week-1-4",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/r/sum.html#week-1-5",
    "href": "ss24/r/sum.html#week-1-5",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/r/sum.html#week-1-6",
    "href": "ss24/r/sum.html#week-1-6",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/r/sum.html#week-1-7",
    "href": "ss24/r/sum.html#week-1-7",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/r/sum.html#week-1-8",
    "href": "ss24/r/sum.html#week-1-8",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/r/sum.html#week-1-9",
    "href": "ss24/r/sum.html#week-1-9",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/r/sum.html#week-1-10",
    "href": "ss24/r/sum.html#week-1-10",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/r/sum.html#week-1-11",
    "href": "ss24/r/sum.html#week-1-11",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss24/r/sum.html#week-1-12",
    "href": "ss24/r/sum.html#week-1-12",
    "title": "Weekly Summary",
    "section": "Week 1",
    "text": "Week 1\n\nLecture 1\ndate:\n\n\nLecture 2\ndate:"
  },
  {
    "objectID": "ss25/alda/index.html",
    "href": "ss25/alda/index.html",
    "title": "Algorithms and Data Structures",
    "section": "",
    "text": "notes\nsolutions\nweekly sum",
    "crumbs": [
      "alda"
    ]
  },
  {
    "objectID": "ss25/alda/sum/w01.html",
    "href": "ss25/alda/sum/w01.html",
    "title": "Week 1",
    "section": "",
    "text": "Heico: Rundmails, Pruefungen\nMaMPF: VL Skript & Videos, Uebungen\nDiscord: Fragen, Teamfindung\nMuesli: Uebungspunkte\nAlgorithms and programming with python (python crashcourse next week)\nwebsite\n\n\n\n\n\n\nAlgorithmus:\n\nloest eint bestimmtes (wohldefiniertes) Problem - “Spezifikation”\nloest das Problem in endlich vielen Schritten - “Komplexitaetstheorie”\nAlle Schritte sind elementar (Bekannte einfache Subalgorithmen)\n\nProblem - Spezifikation:\n\nformale Beschreibung der Aufgabe\nenthaelt nicht die Loesung\n\nVorbedingugen: Notwendiger Zustand der “Welt”, damit der Algorithmus andwendbar ist. (Anforderungen and die Eingaben, evts, auch andere Umbegung)\nNachbedingen: Zustand der “Welt” am Ende des Algoirhtmus.\nBsp: Quadratwurzel \\(y = \\sqrt{x}\\)\n\nVorbedingung: \\(x \\in \\mathbb{N}\\), oder \\(x \\in \\mathbb{R}^{\\geq 0}\\) oder \\(x \\in \\mathbb{R}\\), if \\(y \\in \\mathbb{C}\\)\nNachbedingung: \\(y \\cdot y == x\\), falls Vorbedingung erfuellt, anderfalls, d.h. \\(x \\notin \\mathbb{R}\\), or \\(x &lt; 0\\), dann Fehlermeldung:\n\\(x \\in \\texttt{string}\\): Type error\n\\(x &lt; 0\\): Value error\n\nElementare Schritte:\n\npragmatische Definition: alles, was die Hardware, Programmierscprahe & Standartbibliothek schoin anbietet.\nformale Definition: Theoretische informatik - spezifikation Elementarer Operationen.\n\nBeispiel aus der Geometrie: Konstruktionen mit Zirkel und Lineal\n\nElementare Operationen:\n\ndefniere inen Punkt: (a. beliebig, b. als Schnittpunkt)\nmit Zirkel Abstand zwischen zwei Punkte abgleichen\nmit Zirkel einen Kres um einen geg. Punkt schneiden\n\nRadius beliebig\naus 2)\n\nMit Lineal Gerade durch zwei Punkte zeichnen.\n\n\n\n\nTheoretische Informatik:\n\nZiel der Theoretischen Informatik: mit moeglischst wenig Regeln (Elementare op.) moeglichst viele Algorithmen.\n\\(\\lambda\\)-Calculus\nRecursive Functions Theory\nTuring Machine Computability\nWhile-computability\nUeberraschendes Theorem der Theoretischen Informatik: Die Menge der realisierbaren Algorithmen ist gleich bei allen Systemen (berechenbare Funktionen)\nChurch-Turing These: Es gibt kein maechtigeres Regelsystemen (model of computability).\nwhile-programme:\n\naddition einer Konstante\nsubstraktion einer Konstante\nnacheinander Ausfuehrung zwei Programme (Anweisungen)\nwhile-schleife",
    "crumbs": [
      "Weekly Summary",
      "Week 1"
    ]
  },
  {
    "objectID": "ss25/alda/sum/w01.html#vl-1---15.04.25",
    "href": "ss25/alda/sum/w01.html#vl-1---15.04.25",
    "title": "Week 1",
    "section": "",
    "text": "Heico: Rundmails, Pruefungen\nMaMPF: VL Skript & Videos, Uebungen\nDiscord: Fragen, Teamfindung\nMuesli: Uebungspunkte\nAlgorithms and programming with python (python crashcourse next week)\nwebsite\n\n\n\n\n\n\nAlgorithmus:\n\nloest eint bestimmtes (wohldefiniertes) Problem - “Spezifikation”\nloest das Problem in endlich vielen Schritten - “Komplexitaetstheorie”\nAlle Schritte sind elementar (Bekannte einfache Subalgorithmen)\n\nProblem - Spezifikation:\n\nformale Beschreibung der Aufgabe\nenthaelt nicht die Loesung\n\nVorbedingugen: Notwendiger Zustand der “Welt”, damit der Algorithmus andwendbar ist. (Anforderungen and die Eingaben, evts, auch andere Umbegung)\nNachbedingen: Zustand der “Welt” am Ende des Algoirhtmus.\nBsp: Quadratwurzel \\(y = \\sqrt{x}\\)\n\nVorbedingung: \\(x \\in \\mathbb{N}\\), oder \\(x \\in \\mathbb{R}^{\\geq 0}\\) oder \\(x \\in \\mathbb{R}\\), if \\(y \\in \\mathbb{C}\\)\nNachbedingung: \\(y \\cdot y == x\\), falls Vorbedingung erfuellt, anderfalls, d.h. \\(x \\notin \\mathbb{R}\\), or \\(x &lt; 0\\), dann Fehlermeldung:\n\\(x \\in \\texttt{string}\\): Type error\n\\(x &lt; 0\\): Value error\n\nElementare Schritte:\n\npragmatische Definition: alles, was die Hardware, Programmierscprahe & Standartbibliothek schoin anbietet.\nformale Definition: Theoretische informatik - spezifikation Elementarer Operationen.\n\nBeispiel aus der Geometrie: Konstruktionen mit Zirkel und Lineal\n\nElementare Operationen:\n\ndefniere inen Punkt: (a. beliebig, b. als Schnittpunkt)\nmit Zirkel Abstand zwischen zwei Punkte abgleichen\nmit Zirkel einen Kres um einen geg. Punkt schneiden\n\nRadius beliebig\naus 2)\n\nMit Lineal Gerade durch zwei Punkte zeichnen.\n\n\n\n\nTheoretische Informatik:\n\nZiel der Theoretischen Informatik: mit moeglischst wenig Regeln (Elementare op.) moeglichst viele Algorithmen.\n\\(\\lambda\\)-Calculus\nRecursive Functions Theory\nTuring Machine Computability\nWhile-computability\nUeberraschendes Theorem der Theoretischen Informatik: Die Menge der realisierbaren Algorithmen ist gleich bei allen Systemen (berechenbare Funktionen)\nChurch-Turing These: Es gibt kein maechtigeres Regelsystemen (model of computability).\nwhile-programme:\n\naddition einer Konstante\nsubstraktion einer Konstante\nnacheinander Ausfuehrung zwei Programme (Anweisungen)\nwhile-schleife",
    "crumbs": [
      "Weekly Summary",
      "Week 1"
    ]
  },
  {
    "objectID": "ss25/alda/sum/w01.html#vl-2---17.04.25",
    "href": "ss25/alda/sum/w01.html#vl-2---17.04.25",
    "title": "Week 1",
    "section": "VL 2 - 17.04.25",
    "text": "VL 2 - 17.04.25\n\nMinimal set of elementary operations\n\nwhile-programs:\nset of operations:\n\naccesing a memory cell, read / write: X[i]\nadding a constant \\(c\\) to a memory cell and storing the result in an arbitary cell: X[j] := X[i] + c\nsubstracting a constant \\(c\\) from a memory cell: X[j] := X[i] - c\ncomposition of programs: \\(P\\), \\(Q\\) programs, then \\(P;Q\\) is a program\nwhile loop:\nwhile x[i] != 0 do\n  P // an arbitrary Program\ndone\nin this definition such a while program is valid if x[i] eventually becomes 0. (otherwise, infinite loop =&gt; no algorithm)\ntheorem: with these Elementary operations, all Turing-computable functions can be computed.\nexample: addition of two cells\n\nprecondition: X[j] &gt;= 0\nposcondition: X[i]' == X[i] + X[j]\nimplementation:\nread(X[i]);\nread(X[j]);\n// X[j] &gt;= 0 && X[i] + X[j] == X + Y\nwhile X[j] &gt; 0 do\n  X[j] = X[j] - 1;\n  X[i] = X[i] + 1 \ndone\n// X[j] == 0\n\n\nAround 1400 there was a disagreement about elementary operations. Two camps: Abacus-oriented vs Algorithm-oriented\n\nAbacus-oriented: Roman numerals + abacus operations. (Abacus operations were extremely fast with roman numbers)\nAlgorithm-oriented: how to compute with indian number, pen and paper - based on the book of Al Quarismi.\n\n1500 Adam Ries: “Rechnen auf der Federn und Linien” (Pen and Abacus)\nHeute: pragmatic definition of elementary operations based on the capabilities of the CPU, or on the programming language level the basic operations of the programming language.\n\n\n\nData Structures\nDefinition: Storing data in a way that can be found easily and interpreted correctly.\nExample: Consider sequence of bits: 1101,0110,0110,1100. The ‘meaning’ of this sequence depends on how\nit is interpreted:\n\ninterpretation as a positive binary number.\ninterpretation as a binary integer =&gt; 2s complement.\ninterpreted as a sequence of 8-bit characters:\nimterpreted as a floating point number according to the IEEE standard: S | EEEEE | MMMMMMMMMM\n\nmain point: same symbol can be interpreted in various ways, depending on the system.\n\nprogramming languages: variables have associated types and the compiler or the interpreter determines what type it is and interprets this accordingly.\nFiles:\n\nending of the file .jpg\nmagic number in file”: 255 216 255\ntype standards for communication and Operating system.\n\n\n\nData-structure Triangle\n\n\n\ndata-triangle\n\n\nADT: abstract data type = no implementation is given, no bit sequence is defined. Supported operations and range of values is defined.",
    "crumbs": [
      "Weekly Summary",
      "Week 1"
    ]
  },
  {
    "objectID": "ss25/alda/sum/w03.html",
    "href": "ss25/alda/sum/w03.html",
    "title": "Week 3",
    "section": "",
    "text": "Review of previous lecture; containers: arrays, stack, dictionary\nStack example: redo / undo stacks: stack. Each time an edit is made, it is pushed on the undo stack.\nWhen undo is called, the top of the undo stack is undone, popped, and pushed on the redo stack. When redo is called the converse happens. (What happens when we do not call redo immediately after undo?)\n\n\n\n\nQueue:\n\nOperation: initialization: q = queue(), in python simply a list.\nOperation: top()\npython: s[0] since the top element is the first of the list, and the last as with stacks.\nOperation: pop()\npython: s.pop(0) , since the first element of the queue is the first element of the list. This is not efficient in python, though.\nOperation: push(s, v)\npython: s.append(v)\n\n\n\n\ndouble-ended queue:\n\nefficient both as a stack and as a queue. Remember that pop operation is not efficient for a queue (when list is treated as a queu)\nin python: in the collections module.\nimport collections\nd = collections.deque()\noperations:\n\nd.push(v): push at the end\nd.pop_front() pop first element efficiently\nd.pop_back() pop last element efficienty\n\n\n\n\n\n??\n\n\n\n\n\nMany algorithms work only, (or much faster) on sorted data\nSorting algorihtms are very good example for algorithmic thinking and algorihtm analysis\n\nalgorithmic thinking: in math there are often “existence” proofs, that say that an object exists, but do not prescribe a method to construct such an object. Algorithmic thinking is on the other hand always constructive in finite steps. Usually based on elementary operations. Using iteration and recursion, and principles of divide and conquer.\n\nNote: learning basic algorithms is valuable, but we should very rarely have to implement them from scratch and use library functions instead. (better implemented and more thoroughly tested)\nrules of the game:\n\nunterliegende Containerdatenstrukturen: Array (python list) \\(\\Rightarrow\\) allowed operations: len(a), v = a[i], a[i] = v s.t. i in [0..len(a) - 1]\nThe elements that are to be sorted can be compared: a[i] &lt; a[j] or a[i] &lt;= a[j], elements are totally ordered.\ntotal order:\n\nall pairs of elements can be compared.\nanti-symmetric: a &lt;= b and b &lt;= a ==&gt; a == b (or equivalently a &lt;= b and b =/= a then not b &lt;= a)\ntransitiv: a &lt;= b, b &lt;= c ==&gt; a &lt;= c\nreflexive: a &lt;= a, for all a.\n\n\npractical problem: The elements support u &lt;= v, but the algorithm requires u &lt; v. How to avert this problem?\na &lt; b &lt;=&gt; not(b &lt;= a)\ntheorem: &lt;, &gt;, &gt;=, ==, != all can be implemented with &lt;=, not, and\n\na &lt; b iff not (b &lt;= a)\na &gt; b iff b &lt; a\na &gt;= b iff b &lt;= a\na == b iff a &lt;= b and b &lt;= a\na != b iff not (a == b)\n\n\n\n\nprinciple:\n\nsorintg from left to write (left to the current position is all sorted)\nselect the appropriate element in the right-side of the current position.\n\n\ndef selection_sort(a) :\n    N = len(a)\n    # invariant: sorted(a[0..i-1]) and a[0..i-1] &lt;= a[i..N-1]\n    for i in range(N - 1) :  # iteration\n        j = i \n        # k = i + 1\n        # invariant: a[j] == min(a[i..k-1])\n        for k in range(i + 1, N) : \n            if a[k] &lt; a[j] : j = k\n        a[i], a[j] = a[j], a[i]\n\na = [3, -1, 5, 10]\nselection_sort(a)\nprint(a)\n\n[-1, 3, 5, 10]\n\n\n\n\nHow many steps does selection sort take?\n\nobviously depends on N.",
    "crumbs": [
      "Weekly Summary",
      "Week 3"
    ]
  },
  {
    "objectID": "ss25/alda/sum/w03.html#vl-5---29.04.25",
    "href": "ss25/alda/sum/w03.html#vl-5---29.04.25",
    "title": "Week 3",
    "section": "",
    "text": "Review of previous lecture; containers: arrays, stack, dictionary\nStack example: redo / undo stacks: stack. Each time an edit is made, it is pushed on the undo stack.\nWhen undo is called, the top of the undo stack is undone, popped, and pushed on the redo stack. When redo is called the converse happens. (What happens when we do not call redo immediately after undo?)\n\n\n\n\nQueue:\n\nOperation: initialization: q = queue(), in python simply a list.\nOperation: top()\npython: s[0] since the top element is the first of the list, and the last as with stacks.\nOperation: pop()\npython: s.pop(0) , since the first element of the queue is the first element of the list. This is not efficient in python, though.\nOperation: push(s, v)\npython: s.append(v)\n\n\n\n\ndouble-ended queue:\n\nefficient both as a stack and as a queue. Remember that pop operation is not efficient for a queue (when list is treated as a queu)\nin python: in the collections module.\nimport collections\nd = collections.deque()\noperations:\n\nd.push(v): push at the end\nd.pop_front() pop first element efficiently\nd.pop_back() pop last element efficienty\n\n\n\n\n\n??\n\n\n\n\n\nMany algorithms work only, (or much faster) on sorted data\nSorting algorihtms are very good example for algorithmic thinking and algorihtm analysis\n\nalgorithmic thinking: in math there are often “existence” proofs, that say that an object exists, but do not prescribe a method to construct such an object. Algorithmic thinking is on the other hand always constructive in finite steps. Usually based on elementary operations. Using iteration and recursion, and principles of divide and conquer.\n\nNote: learning basic algorithms is valuable, but we should very rarely have to implement them from scratch and use library functions instead. (better implemented and more thoroughly tested)\nrules of the game:\n\nunterliegende Containerdatenstrukturen: Array (python list) \\(\\Rightarrow\\) allowed operations: len(a), v = a[i], a[i] = v s.t. i in [0..len(a) - 1]\nThe elements that are to be sorted can be compared: a[i] &lt; a[j] or a[i] &lt;= a[j], elements are totally ordered.\ntotal order:\n\nall pairs of elements can be compared.\nanti-symmetric: a &lt;= b and b &lt;= a ==&gt; a == b (or equivalently a &lt;= b and b =/= a then not b &lt;= a)\ntransitiv: a &lt;= b, b &lt;= c ==&gt; a &lt;= c\nreflexive: a &lt;= a, for all a.\n\n\npractical problem: The elements support u &lt;= v, but the algorithm requires u &lt; v. How to avert this problem?\na &lt; b &lt;=&gt; not(b &lt;= a)\ntheorem: &lt;, &gt;, &gt;=, ==, != all can be implemented with &lt;=, not, and\n\na &lt; b iff not (b &lt;= a)\na &gt; b iff b &lt; a\na &gt;= b iff b &lt;= a\na == b iff a &lt;= b and b &lt;= a\na != b iff not (a == b)\n\n\n\n\nprinciple:\n\nsorintg from left to write (left to the current position is all sorted)\nselect the appropriate element in the right-side of the current position.\n\n\ndef selection_sort(a) :\n    N = len(a)\n    # invariant: sorted(a[0..i-1]) and a[0..i-1] &lt;= a[i..N-1]\n    for i in range(N - 1) :  # iteration\n        j = i \n        # k = i + 1\n        # invariant: a[j] == min(a[i..k-1])\n        for k in range(i + 1, N) : \n            if a[k] &lt; a[j] : j = k\n        a[i], a[j] = a[j], a[i]\n\na = [3, -1, 5, 10]\nselection_sort(a)\nprint(a)\n\n[-1, 3, 5, 10]\n\n\n\n\nHow many steps does selection sort take?\n\nobviously depends on N.",
    "crumbs": [
      "Weekly Summary",
      "Week 3"
    ]
  },
  {
    "objectID": "ss25/ibn/index.html",
    "href": "ss25/ibn/index.html",
    "title": "Operating Systems and Networks",
    "section": "",
    "text": "notes\nsolutions\nweekly summary",
    "crumbs": [
      "ibn"
    ]
  },
  {
    "objectID": "ss25/ibn/sum/w01.html",
    "href": "ss25/ibn/sum/w01.html",
    "title": "Week 1",
    "section": "",
    "text": "Definition Betriebssystem: Software, die die Computerhardware verwaltet\nComplexity of an Operating system \\(\\approx\\) 10 mil LOC\nGeschichte der BS:\n\nErste Generation 1941 - 55: Z3, Colossus, Mark I, ENIAC\n\nENIAC: program not stored in memory, rather entered physically by connecting cables.\nEDVAC: implementation of the Von Nuemann architecture, where the program data are both stored in the memory space.\nPrograms were written in Assembler or later Fortran\nProgramming via direct manipulation of cables or later punch-cards.\nNo software that managemes software. Each user/programmer had complete and singular direct use of the hardware, for the time allocated for him/her.\n\n2nd Generation 1955 - 1964\n\nInvention of Transistors =&gt; Commercialization of computers.\nUNIVAC I (1951).\nusual operation:\n\nprogrammer punches his program in chards (either fortran or assembler) and hands them to the operator\noeprator feeds the card deck to the computer system and starts the processing\nafter the process ends the operator goes to the printer and transfers the output to the output room\ninnefiencies:\n\ncomputer spent long idle time during the output. (the output is performed by other machines and takes long time)\na human operator was necessary to load the program and transfer the output.\n\n\nbatch processing:\n\n3rd generation: Multiprogramming =&gt; MULTICS =&gt; Unix\n\nmultiprogramming vs multitasking vs time sharing.",
    "crumbs": [
      "Weekly Summary",
      "Week 1"
    ]
  },
  {
    "objectID": "ss25/ibn/sum/w01.html#vl-1---14.04.25",
    "href": "ss25/ibn/sum/w01.html#vl-1---14.04.25",
    "title": "Week 1",
    "section": "",
    "text": "Definition Betriebssystem: Software, die die Computerhardware verwaltet\nComplexity of an Operating system \\(\\approx\\) 10 mil LOC\nGeschichte der BS:\n\nErste Generation 1941 - 55: Z3, Colossus, Mark I, ENIAC\n\nENIAC: program not stored in memory, rather entered physically by connecting cables.\nEDVAC: implementation of the Von Nuemann architecture, where the program data are both stored in the memory space.\nPrograms were written in Assembler or later Fortran\nProgramming via direct manipulation of cables or later punch-cards.\nNo software that managemes software. Each user/programmer had complete and singular direct use of the hardware, for the time allocated for him/her.\n\n2nd Generation 1955 - 1964\n\nInvention of Transistors =&gt; Commercialization of computers.\nUNIVAC I (1951).\nusual operation:\n\nprogrammer punches his program in chards (either fortran or assembler) and hands them to the operator\noeprator feeds the card deck to the computer system and starts the processing\nafter the process ends the operator goes to the printer and transfers the output to the output room\ninnefiencies:\n\ncomputer spent long idle time during the output. (the output is performed by other machines and takes long time)\na human operator was necessary to load the program and transfer the output.\n\n\nbatch processing:\n\n3rd generation: Multiprogramming =&gt; MULTICS =&gt; Unix\n\nmultiprogramming vs multitasking vs time sharing.",
    "crumbs": [
      "Weekly Summary",
      "Week 1"
    ]
  },
  {
    "objectID": "ss25/ibn/sum/w01.html#vl2---16.04.25",
    "href": "ss25/ibn/sum/w01.html#vl2---16.04.25",
    "title": "Week 1",
    "section": "VL2 - 16.04.25",
    "text": "VL2 - 16.04.25\n\nLecture Notes\n\nprimary tasks of an OS:\n\nan extended machine: a comfortable hardware, abstraction =&gt; System calls, API\nmanagement of resources: processors, I/O devices, memory…\n\navoiding conflicts in multiprogramming and multitasking\nfair allocation of resources\n\n\nComputer architecture crash-course:\n\ncomponets of a PC:\n\nCPU, memeory, busses, secondary memory (hard disks), I/O devices, …\nCPU and other components operate asynchronously and largely independently from each other.\n\nMemory hiearachy, categorized w.r.t. speed, latency, capacity\ncaches = buffer kl\nStack, Stack Pointer, Stack Frames…\n\nexecution modes:\n\nuser mode: some operations are forbidden, restricted access to memory\nkernel mode (priviliged mode)\n\nCPU types:\n\nCISC: powerful but possibly slow instructions\nRISC: simple but fast instructions\nnowadays hybrid, RISC + microcode…\n\nSystem calls: the interface of an OS\nShells, shell scripts",
    "crumbs": [
      "Weekly Summary",
      "Week 1"
    ]
  },
  {
    "objectID": "ss25/ibn/sum/w03.html",
    "href": "ss25/ibn/sum/w03.html",
    "title": "Week 3",
    "section": "",
    "text": "Threads are miniprocesses.\nMain idea: we want concurrency but still retain the recourses of a single process like the data, files and code. (different processes are isolated from each other and don’t share these resources)\nMultithreading is using multiple such threads in a single process \\(\\Rightarrow\\) They all use the same PCB (they coexist within the same process)\nAdvantages of threads w.r.t processes:\n\nsimple comunication between threads, they share the same resources, and it’s faster to synhronize them.\n(no system calls, no switching to kernel mode) Shared resources:\n\ncode\ndata\nfiles\n\nThis makes threads more responsive compared to processes. Different functions of the program can be executed in different threads.\nThreads are more scalabe compared to processes. (There can be much more threads than processes)\n\ntwo types of threads:\n\nuser threads: threads are managed within the process itself\nkernel threads: threads are managed by os globally.\nhow do these two types compare:\n\nswitching between user threads is faster, but since it is not controlled by the os, a blocking thread can slow down the program, whereas in kernel threads the os would issue an interrupt and switch to the next thread. In user threads the os would switch to another process (and switching between processes is in general quite expensive)\nKernel threads: in Multi-Core CPU’s various threads can be distributed among the cores by the us. (not possible in user threads)\n\n\nmixed models:\n\none-to-one\nmany-to-many\nmany-to-one\n\nthreads: threads share state, which enables faster communication, but introduces multitasking-related difficulties, like race conditions. (shared state is both an advantage and a disadvantage of threads)\nprocesses: they are isolated from each other, but this makes the communication difficult\nPOSIX Pthreads: pthread_*. An API for creating, deleting and synchronizing threads. (implementation of APIs exist both as user and kernel threads):\n\n\n\nrace conditions: lost updates \\(\\Rightarrow\\) process synchronization (how to solve such problems)",
    "crumbs": [
      "Weekly Summary",
      "Week 3"
    ]
  },
  {
    "objectID": "ss25/ibn/sum/w03.html#vl-5---28.04.25",
    "href": "ss25/ibn/sum/w03.html#vl-5---28.04.25",
    "title": "Week 3",
    "section": "",
    "text": "Threads are miniprocesses.\nMain idea: we want concurrency but still retain the recourses of a single process like the data, files and code. (different processes are isolated from each other and don’t share these resources)\nMultithreading is using multiple such threads in a single process \\(\\Rightarrow\\) They all use the same PCB (they coexist within the same process)\nAdvantages of threads w.r.t processes:\n\nsimple comunication between threads, they share the same resources, and it’s faster to synhronize them.\n(no system calls, no switching to kernel mode) Shared resources:\n\ncode\ndata\nfiles\n\nThis makes threads more responsive compared to processes. Different functions of the program can be executed in different threads.\nThreads are more scalabe compared to processes. (There can be much more threads than processes)\n\ntwo types of threads:\n\nuser threads: threads are managed within the process itself\nkernel threads: threads are managed by os globally.\nhow do these two types compare:\n\nswitching between user threads is faster, but since it is not controlled by the os, a blocking thread can slow down the program, whereas in kernel threads the os would issue an interrupt and switch to the next thread. In user threads the os would switch to another process (and switching between processes is in general quite expensive)\nKernel threads: in Multi-Core CPU’s various threads can be distributed among the cores by the us. (not possible in user threads)\n\n\nmixed models:\n\none-to-one\nmany-to-many\nmany-to-one\n\nthreads: threads share state, which enables faster communication, but introduces multitasking-related difficulties, like race conditions. (shared state is both an advantage and a disadvantage of threads)\nprocesses: they are isolated from each other, but this makes the communication difficult\nPOSIX Pthreads: pthread_*. An API for creating, deleting and synchronizing threads. (implementation of APIs exist both as user and kernel threads):\n\n\n\nrace conditions: lost updates \\(\\Rightarrow\\) process synchronization (how to solve such problems)",
    "crumbs": [
      "Weekly Summary",
      "Week 3"
    ]
  },
  {
    "objectID": "ss25/ibn/sum/w03.html#vl-6---30.04.25",
    "href": "ss25/ibn/sum/w03.html#vl-6---30.04.25",
    "title": "Week 3",
    "section": "VL 6 - 30.04.25",
    "text": "VL 6 - 30.04.25\nProcess synchronization:\n\nhow can data be communicated from one process to another?\ntaking dependencies into account: if B depends on A, i.e. if B receives data from A, than B should wait for A to be done, before executing.\nProcesses / threads shouldn’t disrupt or block each other.\n\n\nRace Conditions (Continued)\nrace condition: when multiple threads / processes read or write the same variable an update can be lost if one of the threads is interrupted before completing the update.\n\nThe producer - consumer problem: (Slide 8)\n\nproducer: writes to a buffer.\nconsumer: reads from a buffer.\nproblem: count variable is global, therefore an update , either count-- or count++ can get lost, causing count having a wrong final value (Klausurrelevant, Slide 9)\n\nSolution: processes or threads should have critical regions where the execution can not be interrupted - other processes or threads are blocked during this time. \\(\\Rightarrow\\) Mutual Exclusion\n\n\nMutual Exclusion\n\nNo two processes / threads can be executing simulatanously in their critical regions. (critical regions exclude each other)\nA process that is not in its critical region can not block other processes / threads.\n\nhow is it implemented\n\nhardware: a hardware switch (a single bit) is set to 1 when a thread is in its critical region which disables Interrupts.\nsoftware:\n\nprimitive solution: a single boolean variable (this allows only two simultanous threads / processes, therefore very limiting) (Slid 17)\nPeterson’s solution: (slide 19)\n\n\n\nGeneral solution:\n\nLocks and Lock varaibles\nSemaphores\n\n\nLocks\nidea: use a token. The ownership of the token means … (Slide 22)\n\nhardware solutions:\n\ntest and set lock - TSL. (Slide 23)\ninstruction swap - XCHG\n\n\nThese solutions are categorizing under active waiting (or spinlocks) \\(\\Rightarrow\\). Problems: * wasting of processor time. * priority inversoin (Prioritaetsumkehr).\n\n\nSemaphores\n\nintroduced by Dijkstra in 1965\nGeneralization of locks.\ntwo operations:\n\nwait()\nsingal()\n\nhow to implement mutual exclusion with semaphores (slides 29, 30)\nbinary semaphores are also called mutexes.\nlocks can be simulated with semaphores.\nlocks und semaphores (Klausurrelevant, Overview Slide 34, 35)\n\n\n\n\nA Common Situation - Waiting for a Condition / Event\n\nSimple solution - Polling: periodically querry the state of a variable in an infinite loop \\(\\Rightarrow\\) inefficient.\nbetter solution - efficient waiting: the thread is switched to ‘waiting’ state.",
    "crumbs": [
      "Weekly Summary",
      "Week 3"
    ]
  },
  {
    "objectID": "ss25/index.html",
    "href": "ss25/index.html",
    "title": "SS 25",
    "section": "",
    "text": "detailed plan",
    "crumbs": [
      "Bachelor",
      "SS 25"
    ]
  },
  {
    "objectID": "ss25/index.html#schedule",
    "href": "ss25/index.html#schedule",
    "title": "SS 25",
    "section": "",
    "text": "detailed plan",
    "crumbs": [
      "Bachelor",
      "SS 25"
    ]
  },
  {
    "objectID": "ss25/index.html#courses",
    "href": "ss25/index.html#courses",
    "title": "SS 25",
    "section": "Courses",
    "text": "Courses\n\nALDA\nIBN\nSciComp",
    "crumbs": [
      "Bachelor",
      "SS 25"
    ]
  },
  {
    "objectID": "ss25/index.html#time",
    "href": "ss25/index.html#time",
    "title": "SS 25",
    "section": "Time",
    "text": "Time",
    "crumbs": [
      "Bachelor",
      "SS 25"
    ]
  },
  {
    "objectID": "ss25/scicomp/sum/index.html",
    "href": "ss25/scicomp/sum/index.html",
    "title": "Weekly Summary",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nWeek 03\n\n\nApr 29, 2025\n\n\n\n\nWeek 04\n\n\nJun 5, 2025\n\n\n\n\nWeek 1\n\n\n \n\n\n\n\nWeek 2\n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "ss25/scicomp/sum/w02.html",
    "href": "ss25/scicomp/sum/w02.html",
    "title": "Week 2",
    "section": "",
    "text": "overview of scientific computing\nsupercomputing\nc++ basic concepts:"
  },
  {
    "objectID": "ss25/scicomp/sum/w02.html#lecture-2",
    "href": "ss25/scicomp/sum/w02.html#lecture-2",
    "title": "Week 2",
    "section": "",
    "text": "overview of scientific computing\nsupercomputing\nc++ basic concepts:"
  },
  {
    "objectID": "ss25/scicomp/sum/w04.html",
    "href": "ss25/scicomp/sum/w04.html",
    "title": "Week 04",
    "section": "",
    "text": "classes and structs:\n\naccess specifiers. friend keyword\nconversion operators and delegating constructors, explicit keyword.\nconstructors and destructors: rule of five or zero\nmutable keyword\nstatic members, static keyword for functions\ninput / output stream operators\n\nstandard library\n\ncontainers\n\nsequantial containers: std::aray, std::vector, std::deque, std::list, std::forward_list.\nemplace_back() vs push_back()\ncontainer adaptors: implement some data structure in terms of others:\n\nstd::stack, based on std::deque\nstd::queue based on std::deque\nstd::priority_queue based on std::vector\n\nunsorted / sorted associative containers\ncompanion classes: std::pair&lt;T, U&gt;, std::tuple&lt;T..&gt; &lt;T..&gt;\\(\\Rightarrow\\) variadic template\niterators: all container types provide an associated iterator. container T =&gt; T::iterator, allowing iterating over the contents of the container.\n\n\ncurly brace initialization\nforwarding references"
  },
  {
    "objectID": "ss25/scicomp/sum/w04.html#l7---06.05.2025",
    "href": "ss25/scicomp/sum/w04.html#l7---06.05.2025",
    "title": "Week 04",
    "section": "",
    "text": "classes and structs:\n\naccess specifiers. friend keyword\nconversion operators and delegating constructors, explicit keyword.\nconstructors and destructors: rule of five or zero\nmutable keyword\nstatic members, static keyword for functions\ninput / output stream operators\n\nstandard library\n\ncontainers\n\nsequantial containers: std::aray, std::vector, std::deque, std::list, std::forward_list.\nemplace_back() vs push_back()\ncontainer adaptors: implement some data structure in terms of others:\n\nstd::stack, based on std::deque\nstd::queue based on std::deque\nstd::priority_queue based on std::vector\n\nunsorted / sorted associative containers\ncompanion classes: std::pair&lt;T, U&gt;, std::tuple&lt;T..&gt; &lt;T..&gt;\\(\\Rightarrow\\) variadic template\niterators: all container types provide an associated iterator. container T =&gt; T::iterator, allowing iterating over the contents of the container.\n\n\ncurly brace initialization\nforwarding references"
  },
  {
    "objectID": "ws23-24/ipi/ipi.html",
    "href": "ws23-24/ipi/ipi.html",
    "title": "IPI",
    "section": "",
    "text": "weekly summary\nnotes\nsolutions\ncourse website",
    "crumbs": [
      "IPI"
    ]
  },
  {
    "objectID": "ws23-24/num/num.html",
    "href": "ws23-24/num/num.html",
    "title": "Numerics 0",
    "section": "",
    "text": "weekly summary\nnotes\nsolutions",
    "crumbs": [
      "Numerics 0"
    ]
  },
  {
    "objectID": "ws24-25/ds/index.html",
    "href": "ws24-25/ds/index.html",
    "title": "Discrete Structures",
    "section": "",
    "text": "weekly summary\nnotes\nsolutions"
  },
  {
    "objectID": "ws24-25/ds/index.html#section",
    "href": "ws24-25/ds/index.html#section",
    "title": "Discrete Structures",
    "section": "",
    "text": "weekly summary\nnotes\nsolutions"
  },
  {
    "objectID": "ws24-25/index.html#courses",
    "href": "ws24-25/index.html#courses",
    "title": "WS 24/25",
    "section": "Courses",
    "text": "Courses\n\nITS\nISW\nDS",
    "crumbs": [
      "Bachelor",
      "WS 24/25"
    ]
  },
  {
    "objectID": "ws24-25/isw/sum.html",
    "href": "ws24-25/isw/sum.html",
    "title": "My Uni Notes",
    "section": "",
    "text": "date: 15/10/24\nIntro\n\nLOC = lines of code.\nDevelopment time - quality\nSWE at-large vs at-small\nActivities and design decisions\n\norganisatory: moodle pass isw2425\nacrasia\n\n\n\n\n\ndate: 15/10/24\norganisatory infos\njava overview\n\n\n\n\n\ndate: 16/10/24"
  },
  {
    "objectID": "ws24-25/isw/sum.html#week-1",
    "href": "ws24-25/isw/sum.html#week-1",
    "title": "My Uni Notes",
    "section": "",
    "text": "date: 15/10/24\nIntro\n\nLOC = lines of code.\nDevelopment time - quality\nSWE at-large vs at-small\nActivities and design decisions\n\norganisatory: moodle pass isw2425\nacrasia\n\n\n\n\n\ndate: 15/10/24\norganisatory infos\njava overview\n\n\n\n\n\ndate: 16/10/24"
  },
  {
    "objectID": "ws24-25/isw/sum.html#week-2",
    "href": "ws24-25/isw/sum.html#week-2",
    "title": "My Uni Notes",
    "section": "Week 2",
    "text": "Week 2\n\nLecture 1\n\ndate: 22/10/24\nProcess & Project\nTeam organisation\nExtreme programming\nsoftware development tools like git\nrequirements engineering\nGenAI (Uni Heidelberg =&gt; Yoki)\n\n\n\nLecture 2 (tech)\n\ndate: 22/10/24\njava review 2:\n\nInheritence\nObject construction and types casts\nparameter passing: primitive types as value, objects as reference\n\ngit review:\nchatGPT overview"
  },
  {
    "objectID": "ws24-25/isw/sum.html#week-3",
    "href": "ws24-25/isw/sum.html#week-3",
    "title": "My Uni Notes",
    "section": "Week 3",
    "text": "Week 3\n\nLecture 1\n\ndate: 29/10/24\nRequirements Engineering\n\nUsage/User Description\nTask and FuncArrayListtion Description\nGUI Description\n\n\n\n\nLecture 2 (tech)\n\ndate: 29/10/24\ngit\nissue tracking\nandroid basics\n\n\n\nTutorium\n\nQuestions:\nA.3.1:\n\nhow exactly combat score?\n\n\n\n\nA.3.2:\n\nArbeitsbereich?\nUI-Struktur-Diagramm?\nkonkrete Sicht / virtual Windows ?\nexcel datei selbst erstellen oder ist sie auf confluence?\n\nA.3.3:\n\nis MainActivity a UI class or a data class?\nWhat are\n\nRecyclerView ?\nAdapter ?\nViewHolder ?\nimport de.uhd.ifi.pokemonmanager.R ?\n\nLayout Ressourcen fuer MainActivity und RecyclerView?"
  },
  {
    "objectID": "ws24-25/isw/sum.html#week-4",
    "href": "ws24-25/isw/sum.html#week-4",
    "title": "My Uni Notes",
    "section": "Week 4",
    "text": "Week 4\n\nLecture 1\n\ndate: 05/11/24\nui-design principles\nusability\n\n\n\nLecture 2 (tech)\n\ndate: 05/11/24\nsome advanced java stuff"
  },
  {
    "objectID": "ws24-25/isw/sum.html#week-5",
    "href": "ws24-25/isw/sum.html#week-5",
    "title": "My Uni Notes",
    "section": "Week 5",
    "text": "Week 5\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/isw/sum.html#week-6",
    "href": "ws24-25/isw/sum.html#week-6",
    "title": "My Uni Notes",
    "section": "Week 6",
    "text": "Week 6\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/isw/sum.html#week-7",
    "href": "ws24-25/isw/sum.html#week-7",
    "title": "My Uni Notes",
    "section": "Week 7",
    "text": "Week 7\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/isw/sum.html#week-8",
    "href": "ws24-25/isw/sum.html#week-8",
    "title": "My Uni Notes",
    "section": "Week 8",
    "text": "Week 8\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/isw/sum.html#week-9",
    "href": "ws24-25/isw/sum.html#week-9",
    "title": "My Uni Notes",
    "section": "Week 9",
    "text": "Week 9\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/isw/sum.html#week-10",
    "href": "ws24-25/isw/sum.html#week-10",
    "title": "My Uni Notes",
    "section": "Week 10",
    "text": "Week 10\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/isw/sum.html#week-11",
    "href": "ws24-25/isw/sum.html#week-11",
    "title": "My Uni Notes",
    "section": "Week 11",
    "text": "Week 11\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/isw/sum.html#week-12",
    "href": "ws24-25/isw/sum.html#week-12",
    "title": "My Uni Notes",
    "section": "Week 12",
    "text": "Week 12\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/isw/sum.html#week-13",
    "href": "ws24-25/isw/sum.html#week-13",
    "title": "My Uni Notes",
    "section": "Week 13",
    "text": "Week 13\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/isw/sum.html#week-14",
    "href": "ws24-25/isw/sum.html#week-14",
    "title": "My Uni Notes",
    "section": "Week 14",
    "text": "Week 14\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/isw/sum.html#week-15",
    "href": "ws24-25/isw/sum.html#week-15",
    "title": "My Uni Notes",
    "section": "Week 15",
    "text": "Week 15\n\nLecture 1\n\ndate:\n\n\n\nLecture 2\n\ndate:"
  },
  {
    "objectID": "ws24-25/its/sum.html",
    "href": "ws24-25/its/sum.html",
    "title": "Weekly Summary",
    "section": "",
    "text": "date: 14/10/24\nmassive increases in cyber-attacks in last 2-3 years. who is carrying out the attacks? how to find out? Is AI responsible for the increase?\nIntro & infos:\n\nLernziele:\nOrganisational:\n\nwebsite\nall informations/materials on moodle.\n\n\nransomware (check out the wiki article)\nInformation security vs IT-Security: former is a subset of the latter. IT-Security is information security in the realm of electronic information.\nGeneral 3 goals of Information security - CIA:\n\nConfidentiality\nIntegrity\nAvailability\n\nCastle analogy. Thick walls can protect, what about the gates? How to determine who belongs to the castle, who doesn’t? Increasing security measures can directly cause new vulnerabilities.\n\n\n\n\n\ndate: 15/10/24\norganisatory infos:\n\n6 Assignment sheets, 50% for the exam.\ntutorials on heico."
  },
  {
    "objectID": "ws24-25/its/sum.html#week-1",
    "href": "ws24-25/its/sum.html#week-1",
    "title": "Weekly Summary",
    "section": "",
    "text": "date: 14/10/24\nmassive increases in cyber-attacks in last 2-3 years. who is carrying out the attacks? how to find out? Is AI responsible for the increase?\nIntro & infos:\n\nLernziele:\nOrganisational:\n\nwebsite\nall informations/materials on moodle.\n\n\nransomware (check out the wiki article)\nInformation security vs IT-Security: former is a subset of the latter. IT-Security is information security in the realm of electronic information.\nGeneral 3 goals of Information security - CIA:\n\nConfidentiality\nIntegrity\nAvailability\n\nCastle analogy. Thick walls can protect, what about the gates? How to determine who belongs to the castle, who doesn’t? Increasing security measures can directly cause new vulnerabilities.\n\n\n\n\n\ndate: 15/10/24\norganisatory infos:\n\n6 Assignment sheets, 50% for the exam.\ntutorials on heico."
  },
  {
    "objectID": "ws24-25/its/sum.html#week-2",
    "href": "ws24-25/its/sum.html#week-2",
    "title": "Weekly Summary",
    "section": "Week 2",
    "text": "Week 2\n\nLecture\n\ndate: 21/10/24\nhow effective is security by obscurity? (not at all) in fact, open protocols and algorithms enhance security\nISO/OSI Reference modell.\n\nPhysical layer: not part of the lecture\ndata link layer\nnetwork layer\ntransport layer\nsession layer\npresentation layer\napplication layer\n\nsmtp(insecure), ftp, http\n\n\nProtocols\n\nARP: ARP-spoofing, ARP-poisoning (MITM: Man in the Middle)\n\n\n\n\nTutorium\n\ndate: 22/10/24\nSANS penetration testing\nSchwachstelle/Weakness: Any error oder weakness that violates the CIA principles.\n\ne.g:\n\nBedrohung/Threat: Actor, that takes advantage of a weakness\nRisiko/Risk: Damage, that can occur due to a weakness.\nExploit: The actual code or the actual process that takes advantage of the weakness.\nPenetration Test:\n\nScope: IP adress space\nRecon (Reconessence) \\(\\rightarrow\\) Scanning & initial access space \\(\\rightarrow\\) Exploitation \\(\\rightarrow\\) Post-exploitation\nnmap:\n\nTCP:\n\nSyn-pakete\n\nopen\nclosed\nfiltered\nfiltered\n\n\n\nmasscan:"
  },
  {
    "objectID": "ws24-25/its/sum.html#week-3",
    "href": "ws24-25/its/sum.html#week-3",
    "title": "Weekly Summary",
    "section": "Week 3",
    "text": "Week 3\n\nLecture\n\ndate: 28/10/24\nCrytpographic methods\n\nbasic definitions of cryptology, cryptography encryption, decryption, signing data\nClassification of cryptographic algorithms:\n\ncrypotgraphic hash-functions\nsymmetric cryptographic algorithms\nasymmetric cryptographic algorithms\n\nCryptogrpahic check values.\n\nDifference to Information/Coding theory: Coding theory random errors\n\n\ncyrptographic hash functions:\n\ncompression\nease of computation\n…\nmd5, sha-1, sha-2 families\n\n\n\n\nTutorium\n\ndate: 29/10/24 lecture review:\n\nMAC is used for authentication:\n\nMAC(K, msg) = Sha256(k || msg)\n\nct = Enc(k, pt) ct == cypher-text. pt == plain-text.\nEven more securer: ct = Enc(MAC || Enc(pt, K))\nstrong collision resistence implies weak collision resistency.\nx’ collides with x iff h(x) = h(x’)."
  },
  {
    "objectID": "ws24-25/its/sum.html#week-4",
    "href": "ws24-25/its/sum.html#week-4",
    "title": "Weekly Summary",
    "section": "Week 4",
    "text": "Week 4\n\nLecture\n\ndate: 04/11/24\nlecture review:\n\nMDC (Modification Detection Code) (Integrity)\nMAC (Message Authentification Code) (authenticity)\n\nMAC is a cryptographic checksum.\n\nBirthday paradox - relation to hashing.\nSHA\nPasswords\n\nshouldn’t be plain text\nSalt & Pepper (?)\n\nBrute-froce attack\n\nhydra\n\n\n\n\nTutorium\n\ndate: 05/11/24\nwebsites cryptography / cryptoanalhysis challenges:\n\ncryptohack\ncryptopals\njuiceshop\nhackthebox\nctftime.org"
  },
  {
    "objectID": "ws24-25/its/sum.html#week-5",
    "href": "ws24-25/its/sum.html#week-5",
    "title": "Weekly Summary",
    "section": "Week 5",
    "text": "Week 5\n\ndate:"
  },
  {
    "objectID": "ws24-25/its/sum.html#week-6",
    "href": "ws24-25/its/sum.html#week-6",
    "title": "Weekly Summary",
    "section": "Week 6",
    "text": "Week 6\n\ndate:"
  },
  {
    "objectID": "ws24-25/its/sum.html#week-7",
    "href": "ws24-25/its/sum.html#week-7",
    "title": "Weekly Summary",
    "section": "Week 7",
    "text": "Week 7\n\ndate:"
  },
  {
    "objectID": "ws24-25/its/sum.html#week-8",
    "href": "ws24-25/its/sum.html#week-8",
    "title": "Weekly Summary",
    "section": "Week 8",
    "text": "Week 8\n\ndate:"
  },
  {
    "objectID": "ws24-25/its/sum.html#week-9",
    "href": "ws24-25/its/sum.html#week-9",
    "title": "Weekly Summary",
    "section": "Week 9",
    "text": "Week 9\n\ndate:"
  },
  {
    "objectID": "ws24-25/its/sum.html#week-10",
    "href": "ws24-25/its/sum.html#week-10",
    "title": "Weekly Summary",
    "section": "Week 10",
    "text": "Week 10\n\ndate:"
  },
  {
    "objectID": "ws24-25/its/sum.html#week-11",
    "href": "ws24-25/its/sum.html#week-11",
    "title": "Weekly Summary",
    "section": "Week 11",
    "text": "Week 11\n\ndate:"
  },
  {
    "objectID": "ws24-25/its/sum.html#week-12",
    "href": "ws24-25/its/sum.html#week-12",
    "title": "Weekly Summary",
    "section": "Week 12",
    "text": "Week 12\n\ndate:"
  },
  {
    "objectID": "ws24-25/its/sum.html#week-13",
    "href": "ws24-25/its/sum.html#week-13",
    "title": "Weekly Summary",
    "section": "Week 13",
    "text": "Week 13\n\ndate:"
  },
  {
    "objectID": "ws24-25/its/sum.html#week-14",
    "href": "ws24-25/its/sum.html#week-14",
    "title": "Weekly Summary",
    "section": "Week 14",
    "text": "Week 14\n\ndate:"
  },
  {
    "objectID": "ws24-25/its/sum.html#week-15",
    "href": "ws24-25/its/sum.html#week-15",
    "title": "Weekly Summary",
    "section": "Week 15",
    "text": "Week 15\n\ndate:"
  }
]