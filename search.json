[
  {
    "objectID": "ws23-24/ws24-24.html#courses",
    "href": "ws23-24/ws24-24.html#courses",
    "title": "WS 23/24",
    "section": "Courses",
    "text": "Courses\n\nNum\nIPI"
  },
  {
    "objectID": "ws23-24/num/num.html",
    "href": "ws23-24/num/num.html",
    "title": "Numerics 0",
    "section": "",
    "text": "weekly summary\nnotes\nsolutions"
  },
  {
    "objectID": "ws23-24/ipi/ipi.html",
    "href": "ws23-24/ipi/ipi.html",
    "title": "IPI",
    "section": "",
    "text": "weekly summary\nnotes\nsolutions\ncourse website"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "My uni notes & resources"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Uni Notes",
    "section": "",
    "text": "WS 23/24"
  },
  {
    "objectID": "index.html#semesters",
    "href": "index.html#semesters",
    "title": "Uni Notes",
    "section": "",
    "text": "WS 23/24"
  },
  {
    "objectID": "ws23-24/ipi/sum.html",
    "href": "ws23-24/ipi/sum.html",
    "title": "IPI Weekly Summary",
    "section": "",
    "text": "Week 1/~\n\ndate:\nsummary:\n\nWeek 1/~\n\ndate:\nsummary:\n\nWeek 2/VL 1\n\ndate:\nsummary:\n\nWeek 2/VL 2:\n\ndate:\nsummary:"
  },
  {
    "objectID": "ws23-24/num/sum.html",
    "href": "ws23-24/num/sum.html",
    "title": "Num Weekly Summary",
    "section": "",
    "text": "W01/VL01\n\ndate:\nsummary:\n\nW01/VL02\n\ndate:\nsummary:\n\nW02/VL03\n\ndate:\nsummary:\n\nW02/VL04:\n\ndate:\nsummary:\n\nW03/VL05\n\ndate: 31/10/2023, Tue\nsummary: \\(LR\\)-Decomposition, uniqueness, existence, algorithm, complexity, error analysis\n\nScript pages: 21 (satz 2.5) - 28 (2.3 Error Analysis of LR)\nLR Zerlegung ist eindeutig\nProduct of two triangular matrices is also triangular (left or right)\nInverse of a triangular matrix is triangular (left or right)\nProduct of two left-triangular matrices with \\(a_{ii} = 1\\) is also a left-triangular matrix with \\(\\tilde{a}_{ii} = 1\\)\n\\(LR\\)-Decomposition method using Gauss decomposition (Alg 2.7) (?).\nExistence of the \\(LR\\)-decomposition (Satz 2.8)\nPractical version of \\(LR\\)-decomposition Algorithm (not Alg 2.7) saves space (Alg 2.9).\nComplexity of Alg 2.9 and solving a LSE (De: LGS)\nError analysis of \\(LR\\)-Decomposition.\n\n\nW03/VL06\n\ndate: 02/11/23, Thu\nsummary: Script 28 - 33. Error estimation of Alg 2.9, forwards and backwards error, conditioning of a function, conditioning number.\n\nError estimation of Alg 2.9 with proof (Lemma 2.13 & Satz 2.14)\nAposteriori error estimation of Alg 2.9 (Satz 2.16)\nrelationship between backwards and forwards error, a python example demonstrating that they aren’t necessarily related (?)\nConditioning of a function (Ch 2.4.1).\nConditioning number\n\n\nW04/VL07\n\ndate: 07/11/23, Tue\nsummary: Script 33 - 42.\n\nQuestion: How much effect does the error in \\(A\\) & \\(b\\) have on the solutuion of an LEQ/LGS?\nConditioning of a matrix & its proof. (Prop 2.20)\nError analysis of LEQ/LGS’s (Ch 2.4.3)\nConvergent Matrix sequences and matrix series (Ch 2.4.4.)\n\nNeumann Series (2.4.9, P:37)\nSpectral radius of a matrix\n\nConvergent Matrix sequences are used in the proof of error estimation of LEQ/LGS’s. Proof of 2.2.1\nPivoting Strategies to increase \\(LR\\)-decomposition algorithm stability (Ch. 2.5) via exchanging rows during the steps of the algorithm.\n\nPermutation Matrix (Def 2.25)\n\n\n\nW04/VL08\n\ndate: 09/11/23, Thu\nsummary: Script 43 - 51\n\nnote: numbering shifted 1 up, due to a new example\nAlg. 2.27: \\(LR\\)-Decomposition with column pivot search.\n\nSatz 2.30: \\(\\forall\\) regular matrix \\(A \\in \\mathbb{R}^{n\\times n}\\, \\exists\\) a Permutations matrix \\(P_{\\pi}\\), s.t \\(LR = P_{\\pi}A\\) and its proof.\nA problematic matrix for this method: Wilkinson matrix. Such problems can be avoided with “Full Pivot Search/Vollpivotsuche”.\nBut fullpivot search has the disatvantageous complexity \\(\\mathcal{O}(n^3)\\)\n\nCholesky Decomposition: An efficient method for Symmetric Positive Definite (SPD) Matrices.\n\nDefinition & Properties of SPD matrices. (Def 2.32 & Satz 2.33)\nSatz 3.34: \\(A\\in\\mathbb{R}^{n\\times n} \\text{\\, SPD \\, }\\Rightarrow \\exists \\text{\\, upper triangular} \\, R\\in \\mathbb{R}^{n\\times n} \\text{\\, s.t.\\, } A = R^TR\\) (Cholesky decomposition)\nProof of Satz 3.34\nAlgorithm for Cholesky Decomposition (Alg 2.35) and its complexity (\\(\\frac{n^3}{3} + \\mathcal{O}(n^2)\\)). (2 times more efficient than usual decommposition)\n\n\\(LR\\)-Decomposition for Band-matrices\n\nSparce matrices (schwach besetzte matrix) \\(\\approx\\) many entries are 0.\nhow sparce matrices are stored efficiently: For example\n\nA = 0 5 0    C = (2, 3) {non-nul columns}\n    0 0 0    R = (1, 3) {non-null rows}\n    0 0 7    X = (5, 7) {actual entries in these coordinates}\n\nDefinition of a band matrix (Def 2.38)\n\\(LR\\)-decomposition for Band matrices.\n\n\n\nW05/VL09\n\ndate: 14.11.23, Tue\nsummary: Skript 51 - 55 (togehter with topics form appendix)\n\nReview of some LA topics (from Appendix):\n\nDef of orthogonal matrix\nDef of unitary matrix\nLemma A.57/Satz A.58: Singular value decomposition (SVD) and its proof.\nProgramming example demonstrating uses of SVD for image compression.\nProp A.61 regarding SVD (?)\n\nIntro to new Ch 3 - Interpolation & Approximation\n\nOverview of different types of interpolating functions: polynomial, rational (polynomial), spline, neural network\nIntro Polynomial Interpolation:\n\nDef of vector space of polynomials of degree \\(n\\): \\(\\mathbb{P}_n\\).\nDef 3.1: Lagrange Interpolation Polynomials\n\n\n\n\nW05/VL10\n\ndate: 16.11.23, Thu\nsummary: Skript: 55 -\n\nLagrange interpolation\n\nLagrange polynomials \\(\\{l_i\\}_{i=0\\dots n}\\) Form a basis for \\(\\mathbb{P}_n\\) & its proof.\n\nGeneral interpolation with a general basis \\(\\{b_i\\}_{i=0\\dots n}\\) \\(\\Rightarrow\\) Vandermonde Matrix. note: Vandermonde matrix for Lagrange Basis is simply the identity matrix. Vandermonde matrix is very badly conditioned for the monomial basis \\(\\{x^i\\}_{i=0}^n\\)\nError analysis of Lagrange interpolation. Certain properties of the function that is to be interpolated determine the precision of the error analysis (like the smoothness of the function.) (Satz 3.6)\nNeville’s Schema"
  }
]