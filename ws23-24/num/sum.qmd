---
title: Num Weekly Summary
---

* **W01/VL01**
  * **date**: 
  * **summary**: 
* **W01/VL02**
  * **date**:
  * **summary**:
* **W02/VL03**
  * **date**:
  * **summary**:
* **W02/VL04**:
  * **date**:
  * **summary**:
* **W03/VL05**
  * **date**: 10/31/2023, Tue
  * **summary**: $LR$-Decomposition, uniqueness, existence, algorithm, complexity, error analysis
    * Script pages: 21 (satz 2.5) - 28 (2.3 Error Analysis of LR)
    * LR Zerlegung ist eindeutig
    * Product of two triangular matrices is also triangular (left or right)
    * Inverse of a triangular matrix is triangular (left or right)
    * Product of two left-triangular matrices with $a_{ii} = 1$ is also a left-triangular matrix with $\tilde{a}_{ii} = 1$
    * $LR$-Decomposition method using Gauss decomposition (Alg 2.7) (?).
    * Existence of the $LR$-decomposition (Satz 2.8)
    * Practical version of $LR$-decomposition Algorithm (not Alg 2.7) saves space (Alg 2.9).
    * Complexity of Alg 2.9 and solving a LSE (De: LGS)
    * Error analysis of $LR$-Decomposition.
* **W03/VL06**
  * **date**: 02/11/23, Thu
  * **summary**: Script 28 - 33. Error estimation of Alg 2.9, forwards and backwards error, conditioning of a function, conditioning number. 
    * Error estimation of Alg 2.9 with proof (Lemma 2.13 & Satz 2.14)
    * Aposteriori error estimation of Alg 2.9 (Satz 2.16)
    * relationship between backwards and forwards error, a python example demonstrating that they aren't necessarily related (?)
    * Conditioning of a function (Ch 2.4.1). 
    * Conditioning number