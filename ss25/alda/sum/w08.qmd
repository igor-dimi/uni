---
title: Week 8
date: 06/03/2025
---

## VL 15 - 03.06.25

### Complexity (cont.)

* wenn $f(n) in \mathcal{O}(g(N))$ dann gilt fuer die meisten 'interessanten" der **Verschiebungsregel** 
  $f(N + k) \in \mathcal{O}(g(N))$ genau dann, wenn $f(N + k) \leq b^k \cdot f(N)$ fuer konstante $b$ und $N \geq N_k$ gilt.

  **proof**: 
* Examples: 
  * $f(N) = N^D$ for  $D > 0$ (i.e. Monome, roots, ...)
    $f(N + k) = (N + k)^D \leq (2N)^D = 2^D\cdot N^D = 2^D\cdot f(N)$, (here we set $N \geq k$)
  * $f(N) = \log_a N$  $\Rightarrow$ $f(N + k) = \log_a (N + k) = \log_a N \cdot (1 + \frac{k}{N}) \leq ...$
  * $f(N) = a^N \Rightarrow f(N + k) - a^{N + k} = a^k \cdot a^N \rightarrow b = a$
* Basically for these functions the shifting N -> N + k doesn't change the complexity class, (algorihtm will still run longer though)

###  Complexity of Recursive Algorithms

Runtime: $T(N) = T_{\text{local}}(N) + \sum_{i} T_{\text{recursive}}(N_i)$

Two solution methods:

1. recursively substitute the definition of the formula within the sub formulas, until a simpler expression is reached. 
   Even though this might be mathematically not exact it usually allows to guess a formula. 
2. master theorem: 
   
   master theorem can be applied when:

   $$T(N) = T_{\text{local}}(N) + a \cdot T_{\text{recursive}}(N / b)$$

   i.e. $a$ recursive calls with smaller inputs: $\frac{N}{b}$

   * recursions exponent: $\rho = \log_b a$
     
     three cases:

     1. $T_{\text{local}}(N) \in \mathcal{O}(N^{\rho - \epsilon}$, for $\epsilon > 0$. 
        Here the local computation is a little faster than $N^{\rho}$. Then the complexity 

        $$T(N) \in \Theta(N^{\rho})$$

     2. $T_{\text{local}}(N) \in \Theta(N^{\rho})$. Local computation as fast as $N^{\rho}$. Complexity:

        $$T(N) \in \Theta(N^{\rho} \log N)$$

     3. $T_{\text{local}}(N) \in \Omega(N^{\rho + \epsilon})$, for $\epsilon > 0$ and $a\cdot T_{\text{local}}(\frac{N}{b}) \leq c \cdot T_{\text{local}}(N)$, s.t. $c \leq 1$. then local computations dominate and we have:
   
        $$T(N) \in \Theta(T_{\text{local}}(N))$$


### Searching 

* the most important quality criteria of a large DB is a powerful search function
* fundamnetal search types:
  * key search ()
  * range search: keys are in an interval
  * similarity search: finds elements whose keys are similar to the given key $\Rightarrow$ 
    * correcting typing mistakes like google does it
    * content-based search (?)
  * Graph search: shortest path (navigation)


#### Key search

##### Sequential search

* when there is no order, the elements are not order by key
* advantages:
    * no requirements of specifications how the data should be stored
    * the keys must only support "`==`" and don't have to support `<=`. 
* disadvantages: slow, $\mathcal{O}(N)$.
* general implementation:

  ```python
  def sequential_search(a, target_key, key_function):
    for i in ragen(len(a)):
        if key_function(a[i]) == target_key:
            return i # or return a[i]
    return None # not found
  ```

  to simplify, we will omit the explicit usage of `key_function`. Then the elements
  themselves are the keys. But in practice usually a key function is necessary, since elements
  are objects or structures.
  
  The simplified version:

  ```python
  def sequential_search(a, target_key):
    for i in range(len(a)):
        if a[i] == target_key: return i
    return None
  ```

  We want faster searching

##### Faster Searching Algorithms

* to have faster searching we need more information about the keys - they should support more than `==`, 
    * `<=` (total Order): binary search, $\mathcal{O}(\log N)$
    * hash-function: hashtable, $\mathcal{O}(1)$
    * quantize-function: bucketarray, $\mathcal{O}(1)$ (or Bucket sort)

---

* Binary Search: Data are in a sorted array. We need a `<` function.
  
  ```python
  a = [...] # define an unsorted array 
  a.sort()
  found = binary_search(a, key) 
  ```

* implementation:

  ```{python}
  def binary_search_impl(a, key, start, end):
    size = end - start
    if size < 0 : return None # not found
    center = (start + end) // 2
    if a[center] == key: return center
    if a[center] < key: return binary_search_impl(a, key, center + 1, end)
    else : return binary_search_impl(a, key, start, center - 1)
  ```

  ```{python}
  def binary_search(a, key):
    return binary_search_impl(a, key, 0, len(a)) # divide and conquer
  ```

  ```{python}
  a = [2, 1, -3, 4]
  a.sort()
  binary_search(a, 1)
  ```

* complexity analsysi - we apply the master theorem: $T(N) = T_{\text{local}}(N) + a T_{\text{recursive}}(\frac{N}{2})$. Then we have:
  * $T_l = O(1)$
  * $a = 1$
  * $b = 2$
  * $\rho = \log_2 1 = 0 \Rightarrow L_ ...$




